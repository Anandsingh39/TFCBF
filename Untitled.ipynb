{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ddcc46-f67f-4bdd-b151-3487468db121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anandchauhan/anaconda3/envs/gcbfplus/lib/python3.10/site-packages/pytorch_lightning/utilities/cli.py:95: LightningDeprecationWarning: `LightningCLI`'s registries were deprecated in v1.7 and will be removed in v1.9. Now any imported subclass is automatically available by name in `LightningCLI` without any need to explicitly register it.\n",
      "  rank_zero_deprecation(_deprecate_registry_message)\n"
     ]
    }
   ],
   "source": [
    "# model_and_tokenizer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# adjust the import path to your project layout if needed\n",
    "from src.models.modules.modeling_pact import PACTBase\n",
    "# PACTBase wraps PACTTokenizer internally and builds the GPT backbone. :contentReference[oaicite:6]{index=6}\n",
    "\n",
    "def build_pact_model(state_dim=38, action_dim=2, ctx_tokens=16,\n",
    "                     n_embd=128, n_layer=4, n_head=8):\n",
    "    \"\"\"\n",
    "    ctx_tokens = number of tokens the transformer sees (must be even).\n",
    "    Because GPT block_size = 2 * seq_len, set seq_len = ctx_tokens // 2.  :contentReference[oaicite:7]{index=7}\n",
    "    \"\"\"\n",
    "    assert ctx_tokens % 2 == 0, \"ctx_tokens must be even\"\n",
    "    seq_len = ctx_tokens // 2\n",
    "\n",
    "    gpt_config = dict(\n",
    "        n_embd=n_embd, n_layer=n_layer, n_head=n_head,\n",
    "        embd_pdrop=0.1, resid_pdrop=0.1, attn_pdrop=0.1,\n",
    "        seq_len=seq_len\n",
    "    )\n",
    "\n",
    "    # Different tokenizers for \"state\" vs \"action\"\n",
    "    # state -> VectorStateTokenizer (mlp_state)\n",
    "    # action -> ActionTokenizer (mlp_action)\n",
    "    # The action tokenizer handles both continuous and discrete; we use \"continuous\" here. :contentReference[oaicite:8]{index=8} :contentReference[oaicite:9]{index=9}\n",
    "    input_config = {\n",
    "        \"state\": {\n",
    "            \"tokenizer\": \"mlp_state\",\n",
    "            \"input_type\": \"continuous\",\n",
    "            \"tokenizer_kwargs\": {\"state_dim\": state_dim, \"hidden\": [256, 256], \"use_ln\": True},\n",
    "        },\n",
    "        \"action\": {\n",
    "            \"tokenizer\": \"mlp_action\",\n",
    "            \"input_type\": \"continuous\",  # change to \"discrete\" if your actions are ids\n",
    "            \"tokenizer_kwargs\": {\"action_dim\": action_dim, \"hidden\": [128, 128], \"use_ln\": True},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    model = PACTBase(gpt_config=gpt_config, input_config=input_config)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ccc66c-1a22-4b9e-96e6-583096230c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-11-15 16:52:51,207:jax._src.xla_bridge:794: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 256, 'png': 'traj_new.png'}\n"
     ]
    }
   ],
   "source": [
    "from pact_online_agent_mpc_qp_gif_v3 import run_episode_and_save_png\n",
    "\n",
    "# Runs one episode with the new architecture if available (falls back to nominal-only),\n",
    "# and saves a static PNG similar to sa_di_4obs_from_init.png\n",
    "out = run_episode_and_save_png(\n",
    "    path=\"traj_new.png\",\n",
    "    device=\"cpu\",   # switch to \"cuda\" when your CUDA is OK\n",
    "    steps=256,\n",
    "    H=8,            # MPC-like horizon in the new runner\n",
    "    area_size=6.0,\n",
    "    draw_trail=True,\n",
    "    linewidth=2.0,\n",
    "    seed=0\n",
    ")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de7997a-d4e3-461c-9ee4-18aff806aaf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (1813692315.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    x, y = obs['state'][:2] if available\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "x, y = obs['state'][:2] if available\n",
    "gx, gy = obs['goal'][:2] if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1659ad-cf76-4894-b4a2-5321bd302e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ce5cc-3456-4b1f-9137-ee4233daa101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb1d313-218b-4772-9e76-e4f4a4e6891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.py\n",
    "import torch\n",
    "\n",
    "def make_context_window(states, actions, t, ctx_tokens=16, pad_mode=\"repeat_first\"):\n",
    "    \"\"\"\n",
    "    states:  (N, S) float32\n",
    "    actions: (N, A) float32  (or (N,) long for discrete actions)\n",
    "    t:       current time index (0-based), we will produce a window ending at t (inclusive for state)\n",
    "    Returns:\n",
    "      state_seq:  (1, T, S)\n",
    "      action_seq: (1, T, A) or (1, T) for discrete\n",
    "    \"\"\"\n",
    "    assert ctx_tokens % 2 == 0, \"ctx_tokens must be even\"\n",
    "    T = ctx_tokens // 2\n",
    "\n",
    "    S = states.shape[-1]\n",
    "    A = actions.shape[-1] if actions.ndim == 2 else 1\n",
    "\n",
    "    # indices we want\n",
    "    s_start, s_end = t - T + 1, t + 1     # [t-T+1, t] inclusive -> python slice [s_start:s_end)\n",
    "    a_start, a_end = t - T,     t         # [t-T, t-1] inclusive  -> python slice [a_start:a_end)\n",
    "\n",
    "    def left_pad_take(x, start, end, feature_dim, is_action=False):\n",
    "        # x: (N, D)\n",
    "        N = x.shape[0]\n",
    "        if start >= 0:\n",
    "            out = x[start:end]\n",
    "        else:\n",
    "            need = -start\n",
    "            if pad_mode == \"zeros\":\n",
    "                pad = torch.zeros(need, feature_dim, dtype=x.dtype, device=x.device)\n",
    "            else:  # repeat_first\n",
    "                pad = x[0:1].expand(need, feature_dim).clone()\n",
    "            out = torch.cat([pad, x[0:end]], dim=0)\n",
    "        # if we run past the end (rare at episode end), right-pad similarly\n",
    "        if out.shape[0] < (end - start):\n",
    "            need = (end - start) - out.shape[0]\n",
    "            if pad_mode == \"zeros\":\n",
    "                pad = torch.zeros(need, feature_dim, dtype=x.dtype, device=x.device)\n",
    "            else:\n",
    "                pad = x[-1:].expand(need, feature_dim).clone()\n",
    "            out = torch.cat([out, pad], dim=0)\n",
    "        return out\n",
    "\n",
    "    state_win  = left_pad_take(states,  s_start, s_end, S)\n",
    "    if actions.ndim == 2:  # continuous\n",
    "        action_win = left_pad_take(actions, a_start, a_end, A)\n",
    "    else:                  # discrete ids\n",
    "        # treat as (N,1) then squeeze back later\n",
    "        action_win = left_pad_take(actions.view(-1, 1), a_start, a_end, 1).view(-1)\n",
    "\n",
    "    # add batch dim\n",
    "    state_seq  = state_win.unsqueeze(0)                 # (1, T, S)\n",
    "    action_seq = action_win.unsqueeze(0)                # (1, T, A) or (1, T)\n",
    "    return state_seq, action_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f630bd3e-19bf-41d3-9d96-dd3db0c29738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['episode',\n",
       " 'timestep',\n",
       " 'state',\n",
       " 'goal',\n",
       " 'lidar',\n",
       " 'full_obs',\n",
       " 'nominal_action',\n",
       " 'taken_action',\n",
       " 'perturbed',\n",
       " 'mode_excited',\n",
       " 'excitation_direction',\n",
       " 'reward',\n",
       " 'cost',\n",
       " 'safe_mask',\n",
       " 'unsafe_mask',\n",
       " 'collision_mask',\n",
       " 'finish_mask',\n",
       " 'next_state',\n",
       " 'next_full_obs',\n",
       " 'next_safe_mask',\n",
       " 'metadata']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"pact_dataset.npz\", allow_pickle=True)\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5381f60-5cfa-4996-916b-86d799ce6226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 38),\n",
       " array([[-7.4633515e-01,  2.6657838e-01],\n",
       "        [-6.8383753e-01,  2.4425530e-01],\n",
       "        [-6.1303717e-01,  1.6914645e-01],\n",
       "        ...,\n",
       "        [-2.5319010e-03, -4.0341003e-04],\n",
       "        [-2.4128556e-03, -3.6737768e-04],\n",
       "        [-3.3637848e-02,  1.4022903e-02]], shape=(512, 2), dtype=float32),\n",
       " array([[-7.4633515e-01,  2.6657838e-01],\n",
       "        [-6.8383753e-01,  2.4425530e-01],\n",
       "        [-6.2352717e-01,  2.2271338e-01],\n",
       "        ...,\n",
       "        [-2.5319010e-03, -4.0341003e-04],\n",
       "        [-2.4128556e-03, -3.6737768e-04],\n",
       "        [-2.3188367e-03, -3.4411764e-04]], shape=(512, 2), dtype=float32),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['full_obs'].shape, data['taken_action'], data['nominal_action'], data['safe_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523c9247-fdab-48c9-98cb-2b89ba9e8976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': torch.Size([4, 8, 128]), 'action': torch.Size([4, 8, 128])}\n"
     ]
    }
   ],
   "source": [
    "# call_tokenizer_only.py\n",
    "import torch\n",
    "from src.models.modules.tokenizer_pact import PACTTokenizer  # same module PACTBase uses internally\n",
    "# from model_and_tokenizer import build_pact_model\n",
    "\n",
    "# Build the model to get consistent n_embd and tokenizers\n",
    "pact = build_pact_model(state_dim=38, action_dim=2, ctx_tokens=16)\n",
    "tok: PACTTokenizer = pact.tokenizer  # grab the tokenizer PACTBase created\n",
    "\n",
    "# Suppose you already built a window:\n",
    "# state_seq:  (B, T, 38), action_seq: (B, T, 2) or (B, T) discrete\n",
    "# For this example we make dummy data:\n",
    "B, T, S, A = 4, 8, 38, 2\n",
    "state_seq  = torch.randn(B, T, S)\n",
    "action_seq = torch.randn(B, T, A)\n",
    "\n",
    "emb = tok({\"state\": state_seq, \"action\": action_seq})\n",
    "print({k: v.shape for k,v in emb.items()})\n",
    "# {'state': (B, T, n_embd), 'action': (B, T, n_embd)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e664457-bdcb-4373-a61d-8d99f3de7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State tokens (pre)      : (512, 8, 128)\n",
      "Action tokens (pre)     : (512, 8, 128)\n",
      "State ctx (post)        : (512, 8, 128)\n",
      "Action ctx (post)       : (512, 8, 128)\n",
      "Last state ctx (for π)  : (512, 128)\n",
      "Last action ctx (critic): (512, 128)\n"
     ]
    }
   ],
   "source": [
    "# get_embeddings_from_npz.py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --- adjust paths to your repo if needed ---\n",
    "from src.models.modules.modeling_pact import PACTBase          # backbone (tokenizer + GPT)  :contentReference[oaicite:1]{index=1}\n",
    "from src.models.modules.tokenizer_pact import PACTTokenizer     # tokenizer API               :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Build the PACT backbone\n",
    "# ---------------------------\n",
    "def build_pact_model(state_dim=38, action_dim=2, ctx_tokens=16,\n",
    "                     n_embd=128, n_layer=4, n_head=8):\n",
    "    assert ctx_tokens % 2 == 0, \"ctx_tokens must be even\"\n",
    "    seq_len = ctx_tokens // 2  # 16 tokens -> 8 pairs; GPT block_size = 2*seq_len  :contentReference[oaicite:3]{index=3}\n",
    "\n",
    "    gpt_config = dict(\n",
    "        n_embd=n_embd, n_layer=n_layer, n_head=n_head,\n",
    "        embd_pdrop=0.1, resid_pdrop=0.1, attn_pdrop=0.1,\n",
    "        seq_len=seq_len\n",
    "    )\n",
    "\n",
    "    # Different tokenizers for state vs action (both continuous here)\n",
    "    input_config = {\n",
    "        \"state\": {\n",
    "            \"tokenizer\": \"mlp_state\",     # VectorStateTokenizer under the hood\n",
    "            \"input_type\": \"continuous\",\n",
    "            \"tokenizer_kwargs\": {\"state_dim\": state_dim, \"hidden\": [256, 256], \"use_ln\": True},\n",
    "        },\n",
    "        \"action\": {\n",
    "            \"tokenizer\": \"mlp_action\",    # ActionTokenizer under the hood\n",
    "            \"input_type\": \"continuous\",   # set to \"discrete\" if your actions are ids\n",
    "            \"tokenizer_kwargs\": {\"action_dim\": action_dim, \"hidden\": [128, 128], \"use_ln\": True},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # PACTBase = {tokenizer, positional embeddings, GPT(minGPT)}  :contentReference[oaicite:4]{index=4}\n",
    "    model = PACTBase(gpt_config=gpt_config, input_config=input_config)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Context slicing to realize [a_{t-8},..., a_{t-1}, s_t]\n",
    "# --------------------------------------------------------\n",
    "def make_context_window(states, actions, t, ctx_tokens=16, pad_mode=\"repeat_first\"):\n",
    "    \"\"\"\n",
    "    states : (L, S)\n",
    "    actions: (L, A)   (or (L,) for discrete)\n",
    "    Build 8 pairs (T=ctx_tokens//2):\n",
    "        states  -> [s_{t-7}, ..., s_t]      length T\n",
    "        actions -> [a_{t-8}, ..., a_{t-1}]  length T\n",
    "    \"\"\"\n",
    "    assert ctx_tokens % 2 == 0\n",
    "    T = ctx_tokens // 2\n",
    "    S = states.shape[-1]\n",
    "    A = actions.shape[-1] if actions.ndim == 2 else 1\n",
    "\n",
    "    s_start, s_end = t - T + 1, t + 1\n",
    "    a_start, a_end = t - T,     t\n",
    "\n",
    "    def left_pad_take(x, start, end, feat):\n",
    "        # x: (L, feat); returns exactly (end-start, feat)\n",
    "        if start >= 0:\n",
    "            out = x[start:end]\n",
    "        else:\n",
    "            need = -start\n",
    "            pad = np.zeros((need, feat), dtype=x.dtype) if pad_mode == \"zeros\" else np.repeat(x[0:1], need, axis=0)\n",
    "            out = np.concatenate([pad, x[0:end]], axis=0)\n",
    "        if out.shape[0] < (end - start):  # right-pad at episode tail if needed\n",
    "            need = (end - start) - out.shape[0]\n",
    "            pad = np.zeros((need, feat), dtype=x.dtype) if pad_mode == \"zeros\" else np.repeat(x[-1:], need, axis=0)\n",
    "            out = np.concatenate([out, pad], axis=0)\n",
    "        return out\n",
    "\n",
    "    s_win = left_pad_take(states,  s_start, s_end, S)\n",
    "    if actions.ndim == 2:\n",
    "        a_win = left_pad_take(actions, a_start, a_end, A)\n",
    "    else:\n",
    "        a_win = left_pad_take(actions.reshape(-1,1), a_start, a_end, 1).reshape(-1)\n",
    "\n",
    "    # add batch dim -> (1, T, ·)\n",
    "    s_win = torch.as_tensor(s_win, dtype=torch.float32).unsqueeze(0)\n",
    "    a_win = torch.as_tensor(a_win, dtype=torch.float32 if actions.ndim == 2 else torch.long).unsqueeze(0)\n",
    "    return s_win, a_win\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Utilities to split interleaved transformer output streams\n",
    "# ------------------------------------------------------------\n",
    "def split_state_action_embeddings(out_embd):\n",
    "    \"\"\"\n",
    "    out_embd: (B, 2*T, d) interleaved as [state_0, action_0, state_1, action_1, ...]\n",
    "    returns:  state_out:(B,T,d), action_out:(B,T,d)\n",
    "    \"\"\"\n",
    "    return out_embd[:, 0::2, :], out_embd[:, 1::2, :]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) Load npz, group by episode, and compute embeddings\n",
    "# ---------------------------------------------------------\n",
    "def get_embeddings_from_npz(\n",
    "    npz_path,\n",
    "    state_key=\"full_obs\",                 # (N, 38)\n",
    "    action_key=\"taken_action\",            # or \"nominal_action\" (N, 2)\n",
    "    ctx_tokens=16,\n",
    "    n_embd=128\n",
    "):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "\n",
    "    # group into (E, L, ·) using `episode` id\n",
    "    ep_ids = data[\"episode\"].astype(int)          # (N,)\n",
    "    episodes = np.unique(ep_ids)\n",
    "    E = len(episodes)\n",
    "    # derive per-episode length robustly\n",
    "    per_counts = [np.sum(ep_ids == e) for e in episodes]\n",
    "    assert len(set(per_counts)) == 1, \"episodes must have equal length for this simple loader\"\n",
    "    L = per_counts[0]\n",
    "\n",
    "    states_all  = data[state_key].astype(np.float32)     # (N, 38)\n",
    "    actions_all = data[action_key].astype(np.float32)    # (N, 2)\n",
    "\n",
    "    # reshape to (E, L, ·)\n",
    "    S = states_all.shape[-1]\n",
    "    A = actions_all.shape[-1]\n",
    "    states  = np.stack([states_all [ep_ids == e] for e in episodes], axis=0)  # (E, L, 38)\n",
    "    actions = np.stack([actions_all[ep_ids == e] for e in episodes], axis=0)  # (E, L, 2)\n",
    "\n",
    "    # build model (state tokenizer != action tokenizer)\n",
    "    pact = build_pact_model(state_dim=S, action_dim=A, ctx_tokens=ctx_tokens, n_embd=n_embd)\n",
    "\n",
    "    # we’ll build windows for every (episode, t)\n",
    "    T = ctx_tokens // 2\n",
    "    batch_state = []\n",
    "    batch_action = []\n",
    "    map_index = []  # (episode_id, t) for each row in the batch\n",
    "    for e in range(E):\n",
    "        for t in range(L):\n",
    "            s_win, a_win = make_context_window(states[e], actions[e], t, ctx_tokens=ctx_tokens)\n",
    "            batch_state.append(s_win)\n",
    "            batch_action.append(a_win)\n",
    "            map_index.append((episodes[e], t))\n",
    "\n",
    "    batch_state  = torch.cat(batch_state,  dim=0)  # (B, T, 38)  with B=E*L\n",
    "    batch_action = torch.cat(batch_action, dim=0)  # (B, T,  2)\n",
    "\n",
    "    # 4a) TOKENIZER-ONLY: raw token embeddings for state and action (pre-transformer)\n",
    "    # PACTTokenizer.forward expects a dict with tensors shaped (B, T, ·),\n",
    "    # reshapes to each tokenizer's batch_input_size, runs the module, reshapes back to (B,T,n_embd). :contentReference[oaicite:5]{index=5}\n",
    "    tok = pact.tokenizer\n",
    "    tok_res = tok({\"state\": batch_state, \"action\": batch_action})\n",
    "    state_tok = tok_res[\"state\"]   # (B, T, n_embd)\n",
    "    action_tok = tok_res[\"action\"] # (B, T, n_embd)\n",
    "\n",
    "    # 4b) FULL TRANSFORMER: contextualized embeddings\n",
    "    # PACTBase.forward expects {\"state\":(B,T,S), \"action\":(B,T,A)} and returns:\n",
    "    #   out_embd:(B, 2*T, n_embd) interleaved [state_0, action_0, ...]\n",
    "    #   state_tokens:(B, T, n_embd) (pre-transformer state tokens)                                     :contentReference[oaicite:6]{index=6}\n",
    "    with torch.no_grad():\n",
    "        out_embd, state_tokens_in = pact({\"state\": batch_state, \"action\": batch_action})\n",
    "    state_out, action_out = split_state_action_embeddings(out_embd)  # (B,T,d) each\n",
    "\n",
    "    return {\n",
    "        \"map_index\": map_index,              # list of (episode_id, t)\n",
    "        \"state_tokens\": state_tok,           # pre-transformer\n",
    "        \"action_tokens\": action_tok,         # pre-transformer\n",
    "        \"state_ctx\": state_out,              # post-transformer, contextualized\n",
    "        \"action_ctx\": action_out,            # post-transformer, contextualized\n",
    "        \"last_state_ctx\": state_out[:, -1],  # (B, d): embedding of s_t  (useful for policy head later)\n",
    "        \"last_action_ctx\": action_out[:, -1] # (B, d): embedding of a_{t-1} (useful for critic head later)\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    res = get_embeddings_from_npz(\"pact_dataset.npz\",\n",
    "                                  state_key=\"full_obs\",\n",
    "                                  action_key=\"taken_action\",   # or \"nominal_action\"\n",
    "                                  ctx_tokens=16,\n",
    "                                  n_embd=128)\n",
    "    print(\"State tokens (pre)      :\", tuple(res[\"state_tokens\"].shape))   # (B, 8, d)\n",
    "    print(\"Action tokens (pre)     :\", tuple(res[\"action_tokens\"].shape))  # (B, 8, d)\n",
    "    print(\"State ctx (post)        :\", tuple(res[\"state_ctx\"].shape))      # (B, 8, d)\n",
    "    print(\"Action ctx (post)       :\", tuple(res[\"action_ctx\"].shape))     # (B, 8, d)\n",
    "    print(\"Last state ctx (for π)  :\", tuple(res[\"last_state_ctx\"].shape)) # (B, d)\n",
    "    print(\"Last action ctx (critic):\", tuple(res[\"last_action_ctx\"].shape))# (B, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc1c03dd-ef1c-4fd7-8f62-f4a09fe45c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_index': [(np.int64(0), 0),\n",
       "  (np.int64(0), 1),\n",
       "  (np.int64(0), 2),\n",
       "  (np.int64(0), 3),\n",
       "  (np.int64(0), 4),\n",
       "  (np.int64(0), 5),\n",
       "  (np.int64(0), 6),\n",
       "  (np.int64(0), 7),\n",
       "  (np.int64(0), 8),\n",
       "  (np.int64(0), 9),\n",
       "  (np.int64(0), 10),\n",
       "  (np.int64(0), 11),\n",
       "  (np.int64(0), 12),\n",
       "  (np.int64(0), 13),\n",
       "  (np.int64(0), 14),\n",
       "  (np.int64(0), 15),\n",
       "  (np.int64(0), 16),\n",
       "  (np.int64(0), 17),\n",
       "  (np.int64(0), 18),\n",
       "  (np.int64(0), 19),\n",
       "  (np.int64(0), 20),\n",
       "  (np.int64(0), 21),\n",
       "  (np.int64(0), 22),\n",
       "  (np.int64(0), 23),\n",
       "  (np.int64(0), 24),\n",
       "  (np.int64(0), 25),\n",
       "  (np.int64(0), 26),\n",
       "  (np.int64(0), 27),\n",
       "  (np.int64(0), 28),\n",
       "  (np.int64(0), 29),\n",
       "  (np.int64(0), 30),\n",
       "  (np.int64(0), 31),\n",
       "  (np.int64(0), 32),\n",
       "  (np.int64(0), 33),\n",
       "  (np.int64(0), 34),\n",
       "  (np.int64(0), 35),\n",
       "  (np.int64(0), 36),\n",
       "  (np.int64(0), 37),\n",
       "  (np.int64(0), 38),\n",
       "  (np.int64(0), 39),\n",
       "  (np.int64(0), 40),\n",
       "  (np.int64(0), 41),\n",
       "  (np.int64(0), 42),\n",
       "  (np.int64(0), 43),\n",
       "  (np.int64(0), 44),\n",
       "  (np.int64(0), 45),\n",
       "  (np.int64(0), 46),\n",
       "  (np.int64(0), 47),\n",
       "  (np.int64(0), 48),\n",
       "  (np.int64(0), 49),\n",
       "  (np.int64(0), 50),\n",
       "  (np.int64(0), 51),\n",
       "  (np.int64(0), 52),\n",
       "  (np.int64(0), 53),\n",
       "  (np.int64(0), 54),\n",
       "  (np.int64(0), 55),\n",
       "  (np.int64(0), 56),\n",
       "  (np.int64(0), 57),\n",
       "  (np.int64(0), 58),\n",
       "  (np.int64(0), 59),\n",
       "  (np.int64(0), 60),\n",
       "  (np.int64(0), 61),\n",
       "  (np.int64(0), 62),\n",
       "  (np.int64(0), 63),\n",
       "  (np.int64(0), 64),\n",
       "  (np.int64(0), 65),\n",
       "  (np.int64(0), 66),\n",
       "  (np.int64(0), 67),\n",
       "  (np.int64(0), 68),\n",
       "  (np.int64(0), 69),\n",
       "  (np.int64(0), 70),\n",
       "  (np.int64(0), 71),\n",
       "  (np.int64(0), 72),\n",
       "  (np.int64(0), 73),\n",
       "  (np.int64(0), 74),\n",
       "  (np.int64(0), 75),\n",
       "  (np.int64(0), 76),\n",
       "  (np.int64(0), 77),\n",
       "  (np.int64(0), 78),\n",
       "  (np.int64(0), 79),\n",
       "  (np.int64(0), 80),\n",
       "  (np.int64(0), 81),\n",
       "  (np.int64(0), 82),\n",
       "  (np.int64(0), 83),\n",
       "  (np.int64(0), 84),\n",
       "  (np.int64(0), 85),\n",
       "  (np.int64(0), 86),\n",
       "  (np.int64(0), 87),\n",
       "  (np.int64(0), 88),\n",
       "  (np.int64(0), 89),\n",
       "  (np.int64(0), 90),\n",
       "  (np.int64(0), 91),\n",
       "  (np.int64(0), 92),\n",
       "  (np.int64(0), 93),\n",
       "  (np.int64(0), 94),\n",
       "  (np.int64(0), 95),\n",
       "  (np.int64(0), 96),\n",
       "  (np.int64(0), 97),\n",
       "  (np.int64(0), 98),\n",
       "  (np.int64(0), 99),\n",
       "  (np.int64(0), 100),\n",
       "  (np.int64(0), 101),\n",
       "  (np.int64(0), 102),\n",
       "  (np.int64(0), 103),\n",
       "  (np.int64(0), 104),\n",
       "  (np.int64(0), 105),\n",
       "  (np.int64(0), 106),\n",
       "  (np.int64(0), 107),\n",
       "  (np.int64(0), 108),\n",
       "  (np.int64(0), 109),\n",
       "  (np.int64(0), 110),\n",
       "  (np.int64(0), 111),\n",
       "  (np.int64(0), 112),\n",
       "  (np.int64(0), 113),\n",
       "  (np.int64(0), 114),\n",
       "  (np.int64(0), 115),\n",
       "  (np.int64(0), 116),\n",
       "  (np.int64(0), 117),\n",
       "  (np.int64(0), 118),\n",
       "  (np.int64(0), 119),\n",
       "  (np.int64(0), 120),\n",
       "  (np.int64(0), 121),\n",
       "  (np.int64(0), 122),\n",
       "  (np.int64(0), 123),\n",
       "  (np.int64(0), 124),\n",
       "  (np.int64(0), 125),\n",
       "  (np.int64(0), 126),\n",
       "  (np.int64(0), 127),\n",
       "  (np.int64(0), 128),\n",
       "  (np.int64(0), 129),\n",
       "  (np.int64(0), 130),\n",
       "  (np.int64(0), 131),\n",
       "  (np.int64(0), 132),\n",
       "  (np.int64(0), 133),\n",
       "  (np.int64(0), 134),\n",
       "  (np.int64(0), 135),\n",
       "  (np.int64(0), 136),\n",
       "  (np.int64(0), 137),\n",
       "  (np.int64(0), 138),\n",
       "  (np.int64(0), 139),\n",
       "  (np.int64(0), 140),\n",
       "  (np.int64(0), 141),\n",
       "  (np.int64(0), 142),\n",
       "  (np.int64(0), 143),\n",
       "  (np.int64(0), 144),\n",
       "  (np.int64(0), 145),\n",
       "  (np.int64(0), 146),\n",
       "  (np.int64(0), 147),\n",
       "  (np.int64(0), 148),\n",
       "  (np.int64(0), 149),\n",
       "  (np.int64(0), 150),\n",
       "  (np.int64(0), 151),\n",
       "  (np.int64(0), 152),\n",
       "  (np.int64(0), 153),\n",
       "  (np.int64(0), 154),\n",
       "  (np.int64(0), 155),\n",
       "  (np.int64(0), 156),\n",
       "  (np.int64(0), 157),\n",
       "  (np.int64(0), 158),\n",
       "  (np.int64(0), 159),\n",
       "  (np.int64(0), 160),\n",
       "  (np.int64(0), 161),\n",
       "  (np.int64(0), 162),\n",
       "  (np.int64(0), 163),\n",
       "  (np.int64(0), 164),\n",
       "  (np.int64(0), 165),\n",
       "  (np.int64(0), 166),\n",
       "  (np.int64(0), 167),\n",
       "  (np.int64(0), 168),\n",
       "  (np.int64(0), 169),\n",
       "  (np.int64(0), 170),\n",
       "  (np.int64(0), 171),\n",
       "  (np.int64(0), 172),\n",
       "  (np.int64(0), 173),\n",
       "  (np.int64(0), 174),\n",
       "  (np.int64(0), 175),\n",
       "  (np.int64(0), 176),\n",
       "  (np.int64(0), 177),\n",
       "  (np.int64(0), 178),\n",
       "  (np.int64(0), 179),\n",
       "  (np.int64(0), 180),\n",
       "  (np.int64(0), 181),\n",
       "  (np.int64(0), 182),\n",
       "  (np.int64(0), 183),\n",
       "  (np.int64(0), 184),\n",
       "  (np.int64(0), 185),\n",
       "  (np.int64(0), 186),\n",
       "  (np.int64(0), 187),\n",
       "  (np.int64(0), 188),\n",
       "  (np.int64(0), 189),\n",
       "  (np.int64(0), 190),\n",
       "  (np.int64(0), 191),\n",
       "  (np.int64(0), 192),\n",
       "  (np.int64(0), 193),\n",
       "  (np.int64(0), 194),\n",
       "  (np.int64(0), 195),\n",
       "  (np.int64(0), 196),\n",
       "  (np.int64(0), 197),\n",
       "  (np.int64(0), 198),\n",
       "  (np.int64(0), 199),\n",
       "  (np.int64(0), 200),\n",
       "  (np.int64(0), 201),\n",
       "  (np.int64(0), 202),\n",
       "  (np.int64(0), 203),\n",
       "  (np.int64(0), 204),\n",
       "  (np.int64(0), 205),\n",
       "  (np.int64(0), 206),\n",
       "  (np.int64(0), 207),\n",
       "  (np.int64(0), 208),\n",
       "  (np.int64(0), 209),\n",
       "  (np.int64(0), 210),\n",
       "  (np.int64(0), 211),\n",
       "  (np.int64(0), 212),\n",
       "  (np.int64(0), 213),\n",
       "  (np.int64(0), 214),\n",
       "  (np.int64(0), 215),\n",
       "  (np.int64(0), 216),\n",
       "  (np.int64(0), 217),\n",
       "  (np.int64(0), 218),\n",
       "  (np.int64(0), 219),\n",
       "  (np.int64(0), 220),\n",
       "  (np.int64(0), 221),\n",
       "  (np.int64(0), 222),\n",
       "  (np.int64(0), 223),\n",
       "  (np.int64(0), 224),\n",
       "  (np.int64(0), 225),\n",
       "  (np.int64(0), 226),\n",
       "  (np.int64(0), 227),\n",
       "  (np.int64(0), 228),\n",
       "  (np.int64(0), 229),\n",
       "  (np.int64(0), 230),\n",
       "  (np.int64(0), 231),\n",
       "  (np.int64(0), 232),\n",
       "  (np.int64(0), 233),\n",
       "  (np.int64(0), 234),\n",
       "  (np.int64(0), 235),\n",
       "  (np.int64(0), 236),\n",
       "  (np.int64(0), 237),\n",
       "  (np.int64(0), 238),\n",
       "  (np.int64(0), 239),\n",
       "  (np.int64(0), 240),\n",
       "  (np.int64(0), 241),\n",
       "  (np.int64(0), 242),\n",
       "  (np.int64(0), 243),\n",
       "  (np.int64(0), 244),\n",
       "  (np.int64(0), 245),\n",
       "  (np.int64(0), 246),\n",
       "  (np.int64(0), 247),\n",
       "  (np.int64(0), 248),\n",
       "  (np.int64(0), 249),\n",
       "  (np.int64(0), 250),\n",
       "  (np.int64(0), 251),\n",
       "  (np.int64(0), 252),\n",
       "  (np.int64(0), 253),\n",
       "  (np.int64(0), 254),\n",
       "  (np.int64(0), 255),\n",
       "  (np.int64(1), 0),\n",
       "  (np.int64(1), 1),\n",
       "  (np.int64(1), 2),\n",
       "  (np.int64(1), 3),\n",
       "  (np.int64(1), 4),\n",
       "  (np.int64(1), 5),\n",
       "  (np.int64(1), 6),\n",
       "  (np.int64(1), 7),\n",
       "  (np.int64(1), 8),\n",
       "  (np.int64(1), 9),\n",
       "  (np.int64(1), 10),\n",
       "  (np.int64(1), 11),\n",
       "  (np.int64(1), 12),\n",
       "  (np.int64(1), 13),\n",
       "  (np.int64(1), 14),\n",
       "  (np.int64(1), 15),\n",
       "  (np.int64(1), 16),\n",
       "  (np.int64(1), 17),\n",
       "  (np.int64(1), 18),\n",
       "  (np.int64(1), 19),\n",
       "  (np.int64(1), 20),\n",
       "  (np.int64(1), 21),\n",
       "  (np.int64(1), 22),\n",
       "  (np.int64(1), 23),\n",
       "  (np.int64(1), 24),\n",
       "  (np.int64(1), 25),\n",
       "  (np.int64(1), 26),\n",
       "  (np.int64(1), 27),\n",
       "  (np.int64(1), 28),\n",
       "  (np.int64(1), 29),\n",
       "  (np.int64(1), 30),\n",
       "  (np.int64(1), 31),\n",
       "  (np.int64(1), 32),\n",
       "  (np.int64(1), 33),\n",
       "  (np.int64(1), 34),\n",
       "  (np.int64(1), 35),\n",
       "  (np.int64(1), 36),\n",
       "  (np.int64(1), 37),\n",
       "  (np.int64(1), 38),\n",
       "  (np.int64(1), 39),\n",
       "  (np.int64(1), 40),\n",
       "  (np.int64(1), 41),\n",
       "  (np.int64(1), 42),\n",
       "  (np.int64(1), 43),\n",
       "  (np.int64(1), 44),\n",
       "  (np.int64(1), 45),\n",
       "  (np.int64(1), 46),\n",
       "  (np.int64(1), 47),\n",
       "  (np.int64(1), 48),\n",
       "  (np.int64(1), 49),\n",
       "  (np.int64(1), 50),\n",
       "  (np.int64(1), 51),\n",
       "  (np.int64(1), 52),\n",
       "  (np.int64(1), 53),\n",
       "  (np.int64(1), 54),\n",
       "  (np.int64(1), 55),\n",
       "  (np.int64(1), 56),\n",
       "  (np.int64(1), 57),\n",
       "  (np.int64(1), 58),\n",
       "  (np.int64(1), 59),\n",
       "  (np.int64(1), 60),\n",
       "  (np.int64(1), 61),\n",
       "  (np.int64(1), 62),\n",
       "  (np.int64(1), 63),\n",
       "  (np.int64(1), 64),\n",
       "  (np.int64(1), 65),\n",
       "  (np.int64(1), 66),\n",
       "  (np.int64(1), 67),\n",
       "  (np.int64(1), 68),\n",
       "  (np.int64(1), 69),\n",
       "  (np.int64(1), 70),\n",
       "  (np.int64(1), 71),\n",
       "  (np.int64(1), 72),\n",
       "  (np.int64(1), 73),\n",
       "  (np.int64(1), 74),\n",
       "  (np.int64(1), 75),\n",
       "  (np.int64(1), 76),\n",
       "  (np.int64(1), 77),\n",
       "  (np.int64(1), 78),\n",
       "  (np.int64(1), 79),\n",
       "  (np.int64(1), 80),\n",
       "  (np.int64(1), 81),\n",
       "  (np.int64(1), 82),\n",
       "  (np.int64(1), 83),\n",
       "  (np.int64(1), 84),\n",
       "  (np.int64(1), 85),\n",
       "  (np.int64(1), 86),\n",
       "  (np.int64(1), 87),\n",
       "  (np.int64(1), 88),\n",
       "  (np.int64(1), 89),\n",
       "  (np.int64(1), 90),\n",
       "  (np.int64(1), 91),\n",
       "  (np.int64(1), 92),\n",
       "  (np.int64(1), 93),\n",
       "  (np.int64(1), 94),\n",
       "  (np.int64(1), 95),\n",
       "  (np.int64(1), 96),\n",
       "  (np.int64(1), 97),\n",
       "  (np.int64(1), 98),\n",
       "  (np.int64(1), 99),\n",
       "  (np.int64(1), 100),\n",
       "  (np.int64(1), 101),\n",
       "  (np.int64(1), 102),\n",
       "  (np.int64(1), 103),\n",
       "  (np.int64(1), 104),\n",
       "  (np.int64(1), 105),\n",
       "  (np.int64(1), 106),\n",
       "  (np.int64(1), 107),\n",
       "  (np.int64(1), 108),\n",
       "  (np.int64(1), 109),\n",
       "  (np.int64(1), 110),\n",
       "  (np.int64(1), 111),\n",
       "  (np.int64(1), 112),\n",
       "  (np.int64(1), 113),\n",
       "  (np.int64(1), 114),\n",
       "  (np.int64(1), 115),\n",
       "  (np.int64(1), 116),\n",
       "  (np.int64(1), 117),\n",
       "  (np.int64(1), 118),\n",
       "  (np.int64(1), 119),\n",
       "  (np.int64(1), 120),\n",
       "  (np.int64(1), 121),\n",
       "  (np.int64(1), 122),\n",
       "  (np.int64(1), 123),\n",
       "  (np.int64(1), 124),\n",
       "  (np.int64(1), 125),\n",
       "  (np.int64(1), 126),\n",
       "  (np.int64(1), 127),\n",
       "  (np.int64(1), 128),\n",
       "  (np.int64(1), 129),\n",
       "  (np.int64(1), 130),\n",
       "  (np.int64(1), 131),\n",
       "  (np.int64(1), 132),\n",
       "  (np.int64(1), 133),\n",
       "  (np.int64(1), 134),\n",
       "  (np.int64(1), 135),\n",
       "  (np.int64(1), 136),\n",
       "  (np.int64(1), 137),\n",
       "  (np.int64(1), 138),\n",
       "  (np.int64(1), 139),\n",
       "  (np.int64(1), 140),\n",
       "  (np.int64(1), 141),\n",
       "  (np.int64(1), 142),\n",
       "  (np.int64(1), 143),\n",
       "  (np.int64(1), 144),\n",
       "  (np.int64(1), 145),\n",
       "  (np.int64(1), 146),\n",
       "  (np.int64(1), 147),\n",
       "  (np.int64(1), 148),\n",
       "  (np.int64(1), 149),\n",
       "  (np.int64(1), 150),\n",
       "  (np.int64(1), 151),\n",
       "  (np.int64(1), 152),\n",
       "  (np.int64(1), 153),\n",
       "  (np.int64(1), 154),\n",
       "  (np.int64(1), 155),\n",
       "  (np.int64(1), 156),\n",
       "  (np.int64(1), 157),\n",
       "  (np.int64(1), 158),\n",
       "  (np.int64(1), 159),\n",
       "  (np.int64(1), 160),\n",
       "  (np.int64(1), 161),\n",
       "  (np.int64(1), 162),\n",
       "  (np.int64(1), 163),\n",
       "  (np.int64(1), 164),\n",
       "  (np.int64(1), 165),\n",
       "  (np.int64(1), 166),\n",
       "  (np.int64(1), 167),\n",
       "  (np.int64(1), 168),\n",
       "  (np.int64(1), 169),\n",
       "  (np.int64(1), 170),\n",
       "  (np.int64(1), 171),\n",
       "  (np.int64(1), 172),\n",
       "  (np.int64(1), 173),\n",
       "  (np.int64(1), 174),\n",
       "  (np.int64(1), 175),\n",
       "  (np.int64(1), 176),\n",
       "  (np.int64(1), 177),\n",
       "  (np.int64(1), 178),\n",
       "  (np.int64(1), 179),\n",
       "  (np.int64(1), 180),\n",
       "  (np.int64(1), 181),\n",
       "  (np.int64(1), 182),\n",
       "  (np.int64(1), 183),\n",
       "  (np.int64(1), 184),\n",
       "  (np.int64(1), 185),\n",
       "  (np.int64(1), 186),\n",
       "  (np.int64(1), 187),\n",
       "  (np.int64(1), 188),\n",
       "  (np.int64(1), 189),\n",
       "  (np.int64(1), 190),\n",
       "  (np.int64(1), 191),\n",
       "  (np.int64(1), 192),\n",
       "  (np.int64(1), 193),\n",
       "  (np.int64(1), 194),\n",
       "  (np.int64(1), 195),\n",
       "  (np.int64(1), 196),\n",
       "  (np.int64(1), 197),\n",
       "  (np.int64(1), 198),\n",
       "  (np.int64(1), 199),\n",
       "  (np.int64(1), 200),\n",
       "  (np.int64(1), 201),\n",
       "  (np.int64(1), 202),\n",
       "  (np.int64(1), 203),\n",
       "  (np.int64(1), 204),\n",
       "  (np.int64(1), 205),\n",
       "  (np.int64(1), 206),\n",
       "  (np.int64(1), 207),\n",
       "  (np.int64(1), 208),\n",
       "  (np.int64(1), 209),\n",
       "  (np.int64(1), 210),\n",
       "  (np.int64(1), 211),\n",
       "  (np.int64(1), 212),\n",
       "  (np.int64(1), 213),\n",
       "  (np.int64(1), 214),\n",
       "  (np.int64(1), 215),\n",
       "  (np.int64(1), 216),\n",
       "  (np.int64(1), 217),\n",
       "  (np.int64(1), 218),\n",
       "  (np.int64(1), 219),\n",
       "  (np.int64(1), 220),\n",
       "  (np.int64(1), 221),\n",
       "  (np.int64(1), 222),\n",
       "  (np.int64(1), 223),\n",
       "  (np.int64(1), 224),\n",
       "  (np.int64(1), 225),\n",
       "  (np.int64(1), 226),\n",
       "  (np.int64(1), 227),\n",
       "  (np.int64(1), 228),\n",
       "  (np.int64(1), 229),\n",
       "  (np.int64(1), 230),\n",
       "  (np.int64(1), 231),\n",
       "  (np.int64(1), 232),\n",
       "  (np.int64(1), 233),\n",
       "  (np.int64(1), 234),\n",
       "  (np.int64(1), 235),\n",
       "  (np.int64(1), 236),\n",
       "  (np.int64(1), 237),\n",
       "  (np.int64(1), 238),\n",
       "  (np.int64(1), 239),\n",
       "  (np.int64(1), 240),\n",
       "  (np.int64(1), 241),\n",
       "  (np.int64(1), 242),\n",
       "  (np.int64(1), 243),\n",
       "  (np.int64(1), 244),\n",
       "  (np.int64(1), 245),\n",
       "  (np.int64(1), 246),\n",
       "  (np.int64(1), 247),\n",
       "  (np.int64(1), 248),\n",
       "  (np.int64(1), 249),\n",
       "  (np.int64(1), 250),\n",
       "  (np.int64(1), 251),\n",
       "  (np.int64(1), 252),\n",
       "  (np.int64(1), 253),\n",
       "  (np.int64(1), 254),\n",
       "  (np.int64(1), 255)],\n",
       " 'state_tokens': tensor([[[-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          ...,\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231]],\n",
       " \n",
       "         [[-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          ...,\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231]],\n",
       " \n",
       "         [[-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          ...,\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          ...,\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231]],\n",
       " \n",
       "         [[-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          ...,\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231]],\n",
       " \n",
       "         [[-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          ...,\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231],\n",
       "          [-0.0861, -0.0725, -0.1622,  ...,  0.0118,  0.0032, -0.0231]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " 'action_tokens': tensor([[[ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          ...,\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148]],\n",
       " \n",
       "         [[ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          ...,\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148]],\n",
       " \n",
       "         [[ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          ...,\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148],\n",
       "          [ 0.1532, -0.1195, -0.0092,  ..., -0.0141,  0.0543, -0.1148]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1409, -0.1119, -0.0034,  ..., -0.0125,  0.0433, -0.1119],\n",
       "          [ 0.1290, -0.1055,  0.0019,  ..., -0.0110,  0.0325, -0.1095],\n",
       "          [ 0.1171, -0.0998,  0.0070,  ..., -0.0094,  0.0209, -0.1075],\n",
       "          ...,\n",
       "          [ 0.1009, -0.0930,  0.0146,  ..., -0.0064,  0.0017, -0.1059],\n",
       "          [ 0.0992, -0.0923,  0.0155,  ..., -0.0060, -0.0008, -0.1058],\n",
       "          [ 0.0981, -0.0919,  0.0161,  ..., -0.0057, -0.0025, -0.1058]],\n",
       " \n",
       "         [[ 0.1290, -0.1055,  0.0019,  ..., -0.0110,  0.0325, -0.1095],\n",
       "          [ 0.1171, -0.0998,  0.0070,  ..., -0.0094,  0.0209, -0.1075],\n",
       "          [ 0.1087, -0.0962,  0.0108,  ..., -0.0080,  0.0116, -0.1065],\n",
       "          ...,\n",
       "          [ 0.0992, -0.0923,  0.0155,  ..., -0.0060, -0.0008, -0.1058],\n",
       "          [ 0.0981, -0.0919,  0.0161,  ..., -0.0057, -0.0025, -0.1058],\n",
       "          [ 0.0973, -0.0916,  0.0165,  ..., -0.0055, -0.0037, -0.1058]],\n",
       " \n",
       "         [[ 0.1171, -0.0998,  0.0070,  ..., -0.0094,  0.0209, -0.1075],\n",
       "          [ 0.1087, -0.0962,  0.0108,  ..., -0.0080,  0.0116, -0.1065],\n",
       "          [ 0.1037, -0.0941,  0.0131,  ..., -0.0070,  0.0055, -0.1060],\n",
       "          ...,\n",
       "          [ 0.0981, -0.0919,  0.0161,  ..., -0.0057, -0.0025, -0.1058],\n",
       "          [ 0.0973, -0.0916,  0.0165,  ..., -0.0055, -0.0037, -0.1058],\n",
       "          [ 0.0967, -0.0914,  0.0169,  ..., -0.0053, -0.0047, -0.1059]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " 'state_ctx': tensor([[[ 3.6021e-01,  2.5710e-01, -1.4013e+00,  ..., -1.1806e+00,\n",
       "            3.7589e-01, -1.2287e+00],\n",
       "          [ 2.0480e+00, -7.0104e-02, -5.2163e-01,  ..., -6.2538e-01,\n",
       "            4.6116e-02, -1.9523e-01],\n",
       "          [ 1.4444e+00,  4.0115e-01, -1.4168e+00,  ..., -5.0013e-01,\n",
       "           -3.8320e-01, -4.0203e-01],\n",
       "          ...,\n",
       "          [ 1.3692e+00, -3.9143e-01, -8.8297e-01,  ...,  3.8029e-01,\n",
       "            4.8478e-01, -7.6502e-01],\n",
       "          [ 7.4747e-01, -8.1486e-01, -1.4354e+00,  ..., -2.7091e-01,\n",
       "            1.8633e-01, -6.4253e-01],\n",
       "          [ 1.2014e+00,  1.0165e-01, -7.2406e-01,  ...,  7.3676e-01,\n",
       "            2.8348e-01, -3.2165e-01]],\n",
       " \n",
       "         [[ 3.6021e-01,  2.5710e-01, -1.4013e+00,  ..., -1.1806e+00,\n",
       "            3.7589e-01, -1.2287e+00],\n",
       "          [ 2.0480e+00, -7.0104e-02, -5.2163e-01,  ..., -6.2538e-01,\n",
       "            4.6116e-02, -1.9523e-01],\n",
       "          [ 1.4444e+00,  4.0115e-01, -1.4168e+00,  ..., -5.0013e-01,\n",
       "           -3.8320e-01, -4.0203e-01],\n",
       "          ...,\n",
       "          [ 1.3692e+00, -3.9143e-01, -8.8297e-01,  ...,  3.8029e-01,\n",
       "            4.8478e-01, -7.6502e-01],\n",
       "          [ 7.4747e-01, -8.1486e-01, -1.4354e+00,  ..., -2.7091e-01,\n",
       "            1.8633e-01, -6.4253e-01],\n",
       "          [ 1.2014e+00,  1.0165e-01, -7.2406e-01,  ...,  7.3676e-01,\n",
       "            2.8348e-01, -3.2165e-01]],\n",
       " \n",
       "         [[ 3.6021e-01,  2.5710e-01, -1.4013e+00,  ..., -1.1806e+00,\n",
       "            3.7589e-01, -1.2287e+00],\n",
       "          [ 2.0480e+00, -7.0104e-02, -5.2163e-01,  ..., -6.2538e-01,\n",
       "            4.6116e-02, -1.9523e-01],\n",
       "          [ 1.4444e+00,  4.0115e-01, -1.4168e+00,  ..., -5.0013e-01,\n",
       "           -3.8320e-01, -4.0203e-01],\n",
       "          ...,\n",
       "          [ 1.3692e+00, -3.9143e-01, -8.8297e-01,  ...,  3.8029e-01,\n",
       "            4.8478e-01, -7.6502e-01],\n",
       "          [ 7.4747e-01, -8.1486e-01, -1.4354e+00,  ..., -2.7091e-01,\n",
       "            1.8633e-01, -6.4253e-01],\n",
       "          [ 1.2014e+00,  1.0165e-01, -7.2406e-01,  ...,  7.3676e-01,\n",
       "            2.8348e-01, -3.2165e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.6021e-01,  2.5711e-01, -1.4013e+00,  ..., -1.1806e+00,\n",
       "            3.7589e-01, -1.2287e+00],\n",
       "          [ 2.0342e+00, -4.5800e-02, -4.8268e-01,  ..., -6.5793e-01,\n",
       "           -1.9530e-03, -1.6703e-01],\n",
       "          [ 1.4060e+00,  4.5296e-01, -1.3673e+00,  ..., -5.4452e-01,\n",
       "           -4.5605e-01, -3.4472e-01],\n",
       "          ...,\n",
       "          [ 1.2642e+00, -3.1007e-01, -8.3210e-01,  ...,  3.0506e-01,\n",
       "            3.6425e-01, -6.6202e-01],\n",
       "          [ 6.3194e-01, -6.8823e-01, -1.3625e+00,  ..., -3.5385e-01,\n",
       "            3.4024e-02, -4.7358e-01],\n",
       "          [ 1.0441e+00,  2.4000e-01, -6.1767e-01,  ...,  6.2056e-01,\n",
       "            1.2385e-01, -1.7059e-01]],\n",
       " \n",
       "         [[ 3.6021e-01,  2.5710e-01, -1.4013e+00,  ..., -1.1806e+00,\n",
       "            3.7589e-01, -1.2287e+00],\n",
       "          [ 2.0135e+00, -1.9758e-02, -4.3651e-01,  ..., -6.9424e-01,\n",
       "           -5.3696e-02, -1.3602e-01],\n",
       "          [ 1.3748e+00,  4.8370e-01, -1.3159e+00,  ..., -5.8236e-01,\n",
       "           -5.1896e-01, -3.0167e-01],\n",
       "          ...,\n",
       "          [ 1.2374e+00, -2.8982e-01, -7.8422e-01,  ...,  2.7877e-01,\n",
       "            3.1979e-01, -6.2615e-01],\n",
       "          [ 6.1633e-01, -6.6535e-01, -1.3077e+00,  ..., -3.7380e-01,\n",
       "           -1.1604e-02, -4.2876e-01],\n",
       "          [ 1.0231e+00,  2.5528e-01, -5.5594e-01,  ...,  5.9092e-01,\n",
       "            7.9318e-02, -1.3702e-01]],\n",
       " \n",
       "         [[ 3.6021e-01,  2.5710e-01, -1.4013e+00,  ..., -1.1806e+00,\n",
       "            3.7589e-01, -1.2287e+00],\n",
       "          [ 1.9843e+00,  1.0023e-02, -3.7865e-01,  ..., -7.3523e-01,\n",
       "           -1.1226e-01, -1.0142e-01],\n",
       "          [ 1.3439e+00,  5.0871e-01, -1.2550e+00,  ..., -6.2039e-01,\n",
       "           -5.8287e-01, -2.6168e-01],\n",
       "          ...,\n",
       "          [ 1.2154e+00, -2.7635e-01, -7.3316e-01,  ...,  2.5523e-01,\n",
       "            2.8036e-01, -5.9454e-01],\n",
       "          [ 6.0531e-01, -6.5016e-01, -1.2520e+00,  ..., -3.9225e-01,\n",
       "           -5.0781e-02, -3.8963e-01],\n",
       "          [ 1.0065e+00,  2.6410e-01, -4.9419e-01,  ...,  5.6385e-01,\n",
       "            4.0959e-02, -1.0725e-01]]]),\n",
       " 'action_ctx': tensor([[[ 1.1957, -0.6388, -0.3611,  ..., -0.8372,  0.1425, -0.8222],\n",
       "          [ 1.7112, -0.5849,  0.2832,  ..., -0.6353,  0.0305, -0.4820],\n",
       "          [ 1.5036, -0.6836, -0.8554,  ..., -0.9717, -0.2363, -0.3440],\n",
       "          ...,\n",
       "          [ 1.2893, -1.3981, -0.4049,  ..., -0.4515, -0.0969, -0.8190],\n",
       "          [ 1.0045, -1.2132, -0.4578,  ..., -0.4863, -0.2246, -0.7335],\n",
       "          [ 1.0894, -0.7505, -0.1965,  ..., -0.3065,  0.1283, -0.6282]],\n",
       " \n",
       "         [[ 1.1957, -0.6388, -0.3611,  ..., -0.8372,  0.1425, -0.8222],\n",
       "          [ 1.7112, -0.5849,  0.2832,  ..., -0.6353,  0.0305, -0.4820],\n",
       "          [ 1.5036, -0.6836, -0.8554,  ..., -0.9717, -0.2363, -0.3440],\n",
       "          ...,\n",
       "          [ 1.2893, -1.3981, -0.4049,  ..., -0.4515, -0.0969, -0.8190],\n",
       "          [ 1.0045, -1.2132, -0.4578,  ..., -0.4863, -0.2246, -0.7335],\n",
       "          [ 1.0894, -0.7505, -0.1965,  ..., -0.3065,  0.1283, -0.6282]],\n",
       " \n",
       "         [[ 1.1957, -0.6388, -0.3611,  ..., -0.8372,  0.1425, -0.8222],\n",
       "          [ 1.7112, -0.5849,  0.2832,  ..., -0.6353,  0.0305, -0.4820],\n",
       "          [ 1.5036, -0.6836, -0.8554,  ..., -0.9717, -0.2363, -0.3440],\n",
       "          ...,\n",
       "          [ 1.2893, -1.3981, -0.4049,  ..., -0.4515, -0.0969, -0.8190],\n",
       "          [ 1.0045, -1.2132, -0.4578,  ..., -0.4863, -0.2246, -0.7335],\n",
       "          [ 1.0894, -0.7505, -0.1965,  ..., -0.3065,  0.1283, -0.6282]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1973, -0.5816, -0.2823,  ..., -0.8627,  0.0249, -0.8066],\n",
       "          [ 1.7947, -0.5376,  0.5344,  ..., -0.6486, -0.1680, -0.4337],\n",
       "          [ 1.5731, -0.6283, -0.6702,  ..., -1.0494, -0.5913, -0.2494],\n",
       "          ...,\n",
       "          [ 1.2721, -1.4304,  0.0239,  ..., -0.4230, -0.7752, -0.7710],\n",
       "          [ 1.0605, -1.2591,  0.1490,  ..., -0.4348, -0.8365, -0.6364],\n",
       "          [ 1.0314, -0.6536,  0.4037,  ..., -0.1762, -0.3770, -0.6000]],\n",
       " \n",
       "         [[ 1.1847, -0.5269, -0.1960,  ..., -0.8862, -0.1061, -0.7925],\n",
       "          [ 1.8118, -0.5142,  0.6902,  ..., -0.6541, -0.3085, -0.4175],\n",
       "          [ 1.5623, -0.6187, -0.5718,  ..., -1.0649, -0.7406, -0.2300],\n",
       "          ...,\n",
       "          [ 1.2517, -1.4203,  0.0759,  ..., -0.4330, -0.8410, -0.7677],\n",
       "          [ 1.0481, -1.2482,  0.2084,  ..., -0.4426, -0.8850, -0.6247],\n",
       "          [ 1.0173, -0.6476,  0.4552,  ..., -0.1877, -0.4193, -0.5949]],\n",
       " \n",
       "         [[ 1.1568, -0.4723, -0.0959,  ..., -0.9076, -0.2612, -0.7832],\n",
       "          [ 1.8081, -0.4947,  0.8255,  ..., -0.6601, -0.4378, -0.4136],\n",
       "          [ 1.5451, -0.6133, -0.4796,  ..., -1.0790, -0.8592, -0.2188],\n",
       "          ...,\n",
       "          [ 1.2351, -1.4126,  0.1262,  ..., -0.4446, -0.8908, -0.7621],\n",
       "          [ 1.0378, -1.2404,  0.2651,  ..., -0.4524, -0.9231, -0.6124],\n",
       "          [ 1.0062, -0.6447,  0.5064,  ..., -0.2000, -0.4538, -0.5876]]]),\n",
       " 'last_state_ctx': tensor([[ 1.2014,  0.1016, -0.7241,  ...,  0.7368,  0.2835, -0.3217],\n",
       "         [ 1.2014,  0.1016, -0.7241,  ...,  0.7368,  0.2835, -0.3217],\n",
       "         [ 1.2014,  0.1016, -0.7241,  ...,  0.7368,  0.2835, -0.3217],\n",
       "         ...,\n",
       "         [ 1.0441,  0.2400, -0.6177,  ...,  0.6206,  0.1239, -0.1706],\n",
       "         [ 1.0231,  0.2553, -0.5559,  ...,  0.5909,  0.0793, -0.1370],\n",
       "         [ 1.0065,  0.2641, -0.4942,  ...,  0.5638,  0.0410, -0.1072]]),\n",
       " 'last_action_ctx': tensor([[ 1.0894, -0.7505, -0.1965,  ..., -0.3065,  0.1283, -0.6282],\n",
       "         [ 1.0894, -0.7505, -0.1965,  ..., -0.3065,  0.1283, -0.6282],\n",
       "         [ 1.0894, -0.7505, -0.1965,  ..., -0.3065,  0.1283, -0.6282],\n",
       "         ...,\n",
       "         [ 1.0314, -0.6536,  0.4037,  ..., -0.1762, -0.3770, -0.6000],\n",
       "         [ 1.0173, -0.6476,  0.4552,  ..., -0.1877, -0.4193, -0.5949],\n",
       "         [ 1.0062, -0.6447,  0.5064,  ..., -0.2000, -0.4538, -0.5876]])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "baa6c3d6-d502-4e8c-a723-ffb4528682bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0480, -0.0701, -0.5216, -0.1725, -0.3298,  0.4476,  1.1527,  1.1839,\n",
       "        -1.2147,  0.6124,  1.0262,  0.4195, -0.5923, -1.0895, -1.2064,  2.7057,\n",
       "         0.2375,  0.3636,  0.1373,  0.7642, -0.2678,  0.7462, -0.8305,  1.2875,\n",
       "        -0.3518,  0.4703, -0.9122, -0.4408, -0.6101, -0.2000, -1.0604, -0.4307,\n",
       "        -0.8507,  1.5148,  1.0204,  2.6176, -0.1205,  1.2434, -1.2164, -2.6246,\n",
       "         0.3012, -0.6954,  0.9459,  1.3253, -2.5194,  0.5416, -0.5279, -0.6676,\n",
       "        -0.3461, -0.7930, -0.4879,  1.2265, -0.2988,  0.6953, -1.1791,  1.3406,\n",
       "        -0.4869, -0.0754,  0.0365,  0.0827, -1.4684, -0.3380,  0.9199,  0.8276,\n",
       "        -1.1835, -0.7424,  0.1268,  1.8562, -1.5769,  0.0653,  0.7459, -0.3673,\n",
       "        -0.4569,  0.0767,  0.3209, -0.3831, -0.1016, -0.4221,  1.2457,  1.1714,\n",
       "         0.6332,  0.0674,  0.1465, -1.3814,  1.5664,  0.4780,  0.1390,  2.5111,\n",
       "        -0.2360, -0.1777, -1.1005,  0.1730,  0.4403,  0.1814,  0.9782,  0.0600,\n",
       "         0.6889,  1.2567, -0.1481, -0.6199,  1.1833,  0.6630, -1.3545, -1.1393,\n",
       "         0.2414,  1.0946,  1.2981,  0.5209, -0.3573, -0.4085, -0.0996, -2.2855,\n",
       "        -0.9787, -0.3546,  0.2895, -0.8199, -0.0543,  1.5006, -1.2583, -0.8049,\n",
       "        -0.5039, -0.1110, -1.0147, -1.1264, -2.6218, -0.6254,  0.0461, -0.1952])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"state_ctx\"][128,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e7c3481-4d7c-4111-8dbc-224b7473c541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9642e+00,  2.8456e-02, -3.4041e-01, -2.1633e-01, -4.0707e-01,\n",
       "         2.7337e-01,  1.1559e+00,  1.3840e+00, -1.2088e+00,  5.0117e-01,\n",
       "         1.1859e+00,  3.5788e-01, -4.7555e-01, -9.6765e-01, -9.4968e-01,\n",
       "         2.6461e+00,  1.4122e-01,  5.6851e-01,  8.8709e-04,  7.4258e-01,\n",
       "        -3.3957e-01,  8.2526e-01, -8.1111e-01,  1.1132e+00, -3.8673e-01,\n",
       "         5.2711e-01, -8.1755e-01, -5.0024e-01, -4.2218e-01, -6.1392e-02,\n",
       "        -1.0610e+00, -3.6089e-01, -6.5406e-01,  1.6485e+00,  8.4232e-01,\n",
       "         2.6350e+00,  8.0555e-02,  1.1212e+00, -1.1863e+00, -2.6115e+00,\n",
       "         2.4867e-01, -8.6539e-01,  9.6221e-01,  1.5060e+00, -2.4428e+00,\n",
       "         6.1161e-01, -3.3675e-01, -4.8783e-01, -4.1349e-01, -7.7358e-01,\n",
       "        -3.5168e-01,  1.2386e+00, -3.3050e-01,  5.5655e-01, -1.3928e+00,\n",
       "         1.4202e+00, -7.1153e-01,  6.7624e-02, -3.2127e-02,  1.8324e-01,\n",
       "        -1.5678e+00, -2.6022e-01,  1.1370e+00,  5.4777e-01, -1.1423e+00,\n",
       "        -8.8378e-01, -1.4942e-02,  1.6684e+00, -1.4285e+00, -5.7477e-02,\n",
       "         6.1749e-01, -4.3839e-01, -7.5866e-01,  8.9058e-02,  2.7015e-01,\n",
       "        -3.8780e-01, -7.8342e-02, -4.3166e-01,  1.3475e+00,  1.1525e+00,\n",
       "         7.4552e-01, -6.4034e-02,  2.2508e-02, -1.4899e+00,  1.6757e+00,\n",
       "         4.2924e-01, -2.1971e-02,  2.5777e+00, -1.9162e-01, -1.8365e-01,\n",
       "        -1.1462e+00,  1.9020e-01,  4.8912e-01,  3.7146e-01,  9.8202e-01,\n",
       "        -1.0205e-01,  7.7823e-01,  1.3339e+00, -2.8861e-01, -6.8052e-01,\n",
       "         1.0232e+00,  6.1565e-01, -1.0849e+00, -1.2182e+00,  2.1157e-01,\n",
       "         1.3207e+00,  1.1313e+00,  5.6160e-01, -4.5805e-01, -5.9406e-01,\n",
       "         1.4442e-01, -2.0827e+00, -8.8634e-01, -2.7795e-01,  3.1379e-01,\n",
       "        -1.0855e+00,  4.6870e-02,  1.4548e+00, -1.3482e+00, -8.2131e-01,\n",
       "        -4.7482e-01,  3.1914e-03, -1.2327e+00, -1.0838e+00, -2.6186e+00,\n",
       "        -7.5932e-01, -1.4812e-01, -8.1034e-02])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"state_ctx\"][500,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89856d8f-214c-4d52-a7d5-6d8971e386ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "res[\"state_tokens\"][0,1].sum()\n",
    "b = 0\n",
    "cnt = 0\n",
    "for i in range(511):\n",
    "    a = (res[\"action_tokens\"][i,6].sum())\n",
    "    if b!=a:\n",
    "        cnt+=1\n",
    "    b=a\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aed030dd-c5e6-47a8-8d8f-7a1ef37d0bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0556, -0.0401, -0.1370,  0.0920, -0.0862, -0.0241,  0.0740,  0.0038,\n",
       "         0.0044, -0.0126,  0.0894,  0.1270, -0.0315, -0.0830, -0.1333,  0.0984,\n",
       "         0.1279, -0.1858, -0.0250,  0.2726, -0.0262, -0.0331,  0.0440,  0.0454,\n",
       "        -0.0016,  0.0407,  0.0292, -0.0842, -0.1044, -0.1120, -0.1021, -0.0383,\n",
       "        -0.1403, -0.0019, -0.0170,  0.0473, -0.0024,  0.0903, -0.0812, -0.0914,\n",
       "        -0.0434,  0.0774, -0.0287,  0.0032,  0.0018,  0.0413, -0.0979, -0.1425,\n",
       "        -0.0312, -0.1261,  0.0267,  0.1814,  0.0154,  0.0062, -0.0456, -0.0879,\n",
       "        -0.0392,  0.0677,  0.0890,  0.0982,  0.0568,  0.0206,  0.0543, -0.0850,\n",
       "        -0.1078,  0.0638,  0.0238, -0.0575,  0.0347,  0.0992, -0.0069, -0.0034,\n",
       "        -0.0231, -0.0983,  0.0294,  0.0342, -0.0528, -0.0892, -0.0783, -0.0182,\n",
       "         0.0324,  0.0060, -0.0452, -0.0771,  0.0749,  0.0011, -0.0149,  0.0794,\n",
       "        -0.0754, -0.0120,  0.0409,  0.0773,  0.0367, -0.0271, -0.0200, -0.0353,\n",
       "        -0.0628,  0.1960,  0.0926,  0.0079, -0.0471,  0.0346,  0.0048, -0.1211,\n",
       "         0.0003,  0.0437,  0.0893,  0.0134, -0.0058, -0.0770, -0.0188,  0.0059,\n",
       "        -0.1538, -0.0329, -0.0996,  0.0234, -0.0363,  0.1477, -0.1127,  0.0663,\n",
       "        -0.1485,  0.0359, -0.0733, -0.0418,  0.0061,  0.0777,  0.0230, -0.0957],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"state_tokens\"][249,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3d0e2bb-2f81-4a3b-8e0b-5425c928a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pact.eval()  # turn off dropout\n",
    "# with torch.no_grad():\n",
    "#     out1, state_tok1 = pact({\"state\": batch_state, \"action\": batch_action})\n",
    "#     out2, state_tok2 = pact({\"state\": batch_state, \"action\": batch_action})\n",
    "\n",
    "# assert out1.shape == (batch_state.size(0), 2*(batch_state.size(1)), pact.gpt.config[\"n_embd\"])\n",
    "# assert state_tok1.shape == (batch_state.size(0), batch_state.size(1), pact.gpt.config[\"n_embd\"])\n",
    "# assert torch.all(torch.isfinite(out1)) and torch.all(torch.isfinite(state_tok1))\n",
    "# # deterministic in eval mode (no dropout)\n",
    "# assert torch.allclose(out1, out2) and torch.allclose(state_tok1, state_tok2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2e4fe80-8171-4032-ac7f-52edef7a9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_sa(y):  # y: (B, 2T, d)\n",
    "#     return y[:, 0::2, :], y[:, 1::2, :]\n",
    "\n",
    "# out_embd, _ = pact({\"state\": batch_state[:2], \"action\": batch_action[:2]})\n",
    "# state_ctx, action_ctx = split_sa(out_embd)\n",
    "# assert state_ctx.shape[:2] == action_ctx.shape[:2] == (2, batch_state.size(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e018e90b-1869-4fbe-a916-9d57c49d10f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mbatch_state\u001b[49m\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_action\u001b[38;5;241m.\u001b[39mfloat()}\n\u001b[1;32m      2\u001b[0m out1, state_tok1 \u001b[38;5;241m=\u001b[39m pact(batch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_state' is not defined"
     ]
    }
   ],
   "source": [
    "batch = {\"state\": batch_state.float(), \"action\": batch_action.float()}\n",
    "out1, state_tok1 = pact(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fed672a8-e598-4735-9c86-13de0585862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Demo outputs ===\n",
      "state_seq: (256, 8, 38) action_seq: (256, 8, 2)\n",
      "policy_out: (256, 2) critic_out: (256, 1)\n",
      "state_ctx: (256, 8, 128) action_ctx: (256, 8, 128)\n",
      "last_state_ctx: (256, 128) last_action_ctx: (256, 128)\n"
     ]
    }
   ],
   "source": [
    "from src.models.modules import a\n",
    "a.CFG.device = \"cpu\"           # override the default\n",
    "res = a.run_demo(\"pact_dataset.npz\",\n",
    "                 state_key=\"full_obs\",\n",
    "                 action_key=\"taken_action\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "488330bb-18f0-4dec-9f84-3b1a1dd6aa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy_out': tensor([[0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0946, 0.0522],\n",
       "         [0.0945, 0.0516],\n",
       "         [0.0944, 0.0509],\n",
       "         [0.0940, 0.0670],\n",
       "         [0.0919, 0.0645],\n",
       "         [0.0898, 0.0614],\n",
       "         [0.1121, 0.0690],\n",
       "         [0.1102, 0.0641],\n",
       "         [0.1102, 0.0636],\n",
       "         [0.1110, 0.0628],\n",
       "         [0.0963, 0.0664],\n",
       "         [0.0969, 0.0660],\n",
       "         [0.0975, 0.0652],\n",
       "         [0.0994, 0.0633],\n",
       "         [0.0988, 0.0625],\n",
       "         [0.0981, 0.0615],\n",
       "         [0.1192, 0.0441],\n",
       "         [0.1172, 0.0449],\n",
       "         [0.1169, 0.0467],\n",
       "         [0.1163, 0.0484],\n",
       "         [0.1152, 0.0502],\n",
       "         [0.1138, 0.0520],\n",
       "         [0.1197, 0.0798],\n",
       "         [0.1150, 0.0621],\n",
       "         [0.1066, 0.0511],\n",
       "         [0.1220, 0.0528],\n",
       "         [0.1187, 0.0516],\n",
       "         [0.1151, 0.0500],\n",
       "         [0.1111, 0.0477],\n",
       "         [0.0929, 0.0408],\n",
       "         [0.0988, 0.0433],\n",
       "         [0.0987, 0.0393],\n",
       "         [0.0999, 0.0611],\n",
       "         [0.1045, 0.0630],\n",
       "         [0.1081, 0.0432],\n",
       "         [0.1133, 0.0689],\n",
       "         [0.1184, 0.0747],\n",
       "         [0.1184, 0.0795],\n",
       "         [0.1191, 0.0803],\n",
       "         [0.1192, 0.0827],\n",
       "         [0.1197, 0.0822],\n",
       "         [0.1126, 0.0554],\n",
       "         [0.1114, 0.0582],\n",
       "         [0.1102, 0.0582],\n",
       "         [0.0900, 0.0725],\n",
       "         [0.0890, 0.0706],\n",
       "         [0.0882, 0.0685],\n",
       "         [0.1082, 0.0519],\n",
       "         [0.0868, 0.0662],\n",
       "         [0.0878, 0.0647],\n",
       "         [0.0900, 0.0630],\n",
       "         [0.0948, 0.0608],\n",
       "         [0.0945, 0.0609],\n",
       "         [0.1096, 0.0571],\n",
       "         [0.1072, 0.0592],\n",
       "         [0.1129, 0.0583],\n",
       "         [0.1134, 0.0594],\n",
       "         [0.1142, 0.0601],\n",
       "         [0.1150, 0.0608],\n",
       "         [0.1160, 0.0612],\n",
       "         [0.0935, 0.0495],\n",
       "         [0.0935, 0.0485],\n",
       "         [0.0932, 0.0475],\n",
       "         [0.0943, 0.0303],\n",
       "         [0.0960, 0.0305],\n",
       "         [0.0594, 0.0403],\n",
       "         [0.0597, 0.0422],\n",
       "         [0.0578, 0.0461],\n",
       "         [0.0589, 0.0493],\n",
       "         [0.0592, 0.0531],\n",
       "         [0.0568, 0.0574],\n",
       "         [0.0584, 0.0601],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0651],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0605, 0.0652],\n",
       "         [0.0947, 0.0522],\n",
       "         [0.0947, 0.0691],\n",
       "         [0.0929, 0.0671],\n",
       "         [0.1154, 0.0757],\n",
       "         [0.0897, 0.0633],\n",
       "         [0.0885, 0.0598],\n",
       "         [0.0878, 0.0519],\n",
       "         [0.0860, 0.0451],\n",
       "         [0.1127, 0.0560],\n",
       "         [0.1132, 0.0571],\n",
       "         [0.1137, 0.0536],\n",
       "         [0.1103, 0.0514],\n",
       "         [0.1056, 0.0538],\n",
       "         [0.0887, 0.0446],\n",
       "         [0.1117, 0.0500],\n",
       "         [0.1095, 0.0483],\n",
       "         [0.1020, 0.0419],\n",
       "         [0.1042, 0.0419],\n",
       "         [0.1082, 0.0433],\n",
       "         [0.1009, 0.0358],\n",
       "         [0.1003, 0.0381],\n",
       "         [0.1065, 0.0366],\n",
       "         [0.0981, 0.0349],\n",
       "         [0.0991, 0.0409],\n",
       "         [0.1005, 0.0410],\n",
       "         [0.1019, 0.0408],\n",
       "         [0.1040, 0.0419],\n",
       "         [0.1067, 0.0434],\n",
       "         [0.1123, 0.0492],\n",
       "         [0.1074, 0.0437],\n",
       "         [0.0998, 0.0350],\n",
       "         [0.1000, 0.0352],\n",
       "         [0.1017, 0.0353],\n",
       "         [0.1026, 0.0361],\n",
       "         [0.1065, 0.0367],\n",
       "         [0.0979, 0.0297],\n",
       "         [0.0983, 0.0355],\n",
       "         [0.0748, 0.0470],\n",
       "         [0.0755, 0.0452],\n",
       "         [0.0990, 0.0382],\n",
       "         [0.1009, 0.0388],\n",
       "         [0.1029, 0.0398],\n",
       "         [0.1071, 0.0413],\n",
       "         [0.0994, 0.0342],\n",
       "         [0.0997, 0.0353],\n",
       "         [0.1048, 0.0365],\n",
       "         [0.0980, 0.0302],\n",
       "         [0.0981, 0.0304],\n",
       "         [0.0981, 0.0305],\n",
       "         [0.0982, 0.0307],\n",
       "         [0.0983, 0.0308],\n",
       "         [0.0983, 0.0310],\n",
       "         [0.0984, 0.0311],\n",
       "         [0.0984, 0.0312],\n",
       "         [0.0984, 0.0310],\n",
       "         [0.0986, 0.0361],\n",
       "         [0.0991, 0.0412],\n",
       "         [0.1012, 0.0462],\n",
       "         [0.1036, 0.0481],\n",
       "         [0.1071, 0.0529],\n",
       "         [0.1107, 0.0545],\n",
       "         [0.1189, 0.0560],\n",
       "         [0.1157, 0.0530],\n",
       "         [0.0882, 0.0429],\n",
       "         [0.0818, 0.0362],\n",
       "         [0.0835, 0.0337],\n",
       "         [0.0757, 0.0267],\n",
       "         [0.0769, 0.0255],\n",
       "         [0.0767, 0.0253],\n",
       "         [0.1027, 0.0331],\n",
       "         [0.0926, 0.0355],\n",
       "         [0.0944, 0.0407],\n",
       "         [0.0959, 0.0408],\n",
       "         [0.0973, 0.0416],\n",
       "         [0.1000, 0.0483],\n",
       "         [0.1032, 0.0538],\n",
       "         [0.1122, 0.0519],\n",
       "         [0.1062, 0.0444],\n",
       "         [0.1036, 0.0451],\n",
       "         [0.1068, 0.0506],\n",
       "         [0.1134, 0.0553],\n",
       "         [0.1107, 0.0505],\n",
       "         [0.1059, 0.0501],\n",
       "         [0.1106, 0.0550],\n",
       "         [0.1193, 0.0571],\n",
       "         [0.1160, 0.0533],\n",
       "         [0.1131, 0.0537],\n",
       "         [0.1066, 0.0544],\n",
       "         [0.1132, 0.0591],\n",
       "         [0.1089, 0.0516],\n",
       "         [0.1080, 0.0474],\n",
       "         [0.1088, 0.0469],\n",
       "         [0.1159, 0.0524],\n",
       "         [0.1124, 0.0524],\n",
       "         [0.1089, 0.0466],\n",
       "         [0.1016, 0.0403],\n",
       "         [0.1039, 0.0407],\n",
       "         [0.1068, 0.0417],\n",
       "         [0.1117, 0.0431]]),\n",
       " 'critic_out': tensor([[0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0919],\n",
       "         [0.0915],\n",
       "         [0.0908],\n",
       "         [0.0908],\n",
       "         [0.0908],\n",
       "         [0.0906],\n",
       "         [0.0908],\n",
       "         [0.0905],\n",
       "         [0.0926],\n",
       "         [0.0953],\n",
       "         [0.0984],\n",
       "         [0.0983],\n",
       "         [0.0978],\n",
       "         [0.0976],\n",
       "         [0.0966],\n",
       "         [0.0954],\n",
       "         [0.0924],\n",
       "         [0.0879],\n",
       "         [0.0868],\n",
       "         [0.0858],\n",
       "         [0.0845],\n",
       "         [0.0832],\n",
       "         [0.0813],\n",
       "         [0.0797],\n",
       "         [0.0796],\n",
       "         [0.0803],\n",
       "         [0.0803],\n",
       "         [0.0802],\n",
       "         [0.0793],\n",
       "         [0.0770],\n",
       "         [0.0777],\n",
       "         [0.0779],\n",
       "         [0.0769],\n",
       "         [0.0763],\n",
       "         [0.0767],\n",
       "         [0.0764],\n",
       "         [0.0766],\n",
       "         [0.0752],\n",
       "         [0.0742],\n",
       "         [0.0732],\n",
       "         [0.0733],\n",
       "         [0.0737],\n",
       "         [0.0732],\n",
       "         [0.0737],\n",
       "         [0.0758],\n",
       "         [0.0780],\n",
       "         [0.0803],\n",
       "         [0.0815],\n",
       "         [0.0849],\n",
       "         [0.0861],\n",
       "         [0.0874],\n",
       "         [0.0890],\n",
       "         [0.0891],\n",
       "         [0.0893],\n",
       "         [0.0892],\n",
       "         [0.0914],\n",
       "         [0.0921],\n",
       "         [0.0931],\n",
       "         [0.0944],\n",
       "         [0.0963],\n",
       "         [0.0993],\n",
       "         [0.0990],\n",
       "         [0.0987],\n",
       "         [0.0976],\n",
       "         [0.0964],\n",
       "         [0.0954],\n",
       "         [0.0941],\n",
       "         [0.0925],\n",
       "         [0.0918],\n",
       "         [0.0907],\n",
       "         [0.0888],\n",
       "         [0.0905],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0922],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0923],\n",
       "         [0.0918],\n",
       "         [0.0923],\n",
       "         [0.0926],\n",
       "         [0.0934],\n",
       "         [0.0937],\n",
       "         [0.1020],\n",
       "         [0.0969],\n",
       "         [0.0955],\n",
       "         [0.0960],\n",
       "         [0.1031],\n",
       "         [0.1123],\n",
       "         [0.0962],\n",
       "         [0.1111],\n",
       "         [0.1191],\n",
       "         [0.1082],\n",
       "         [0.1173],\n",
       "         [0.1168],\n",
       "         [0.1162],\n",
       "         [0.1198],\n",
       "         [0.1160],\n",
       "         [0.1176],\n",
       "         [0.1023],\n",
       "         [0.0898],\n",
       "         [0.1097],\n",
       "         [0.1132],\n",
       "         [0.1134],\n",
       "         [0.1148],\n",
       "         [0.1051],\n",
       "         [0.1179],\n",
       "         [0.1199],\n",
       "         [0.1145],\n",
       "         [0.1143],\n",
       "         [0.1147],\n",
       "         [0.1153],\n",
       "         [0.1177],\n",
       "         [0.0952],\n",
       "         [0.1137],\n",
       "         [0.1145],\n",
       "         [0.0977],\n",
       "         [0.1117],\n",
       "         [0.1133],\n",
       "         [0.1127],\n",
       "         [0.1153],\n",
       "         [0.1116],\n",
       "         [0.1102],\n",
       "         [0.1138],\n",
       "         [0.1140],\n",
       "         [0.1140],\n",
       "         [0.1140],\n",
       "         [0.1140],\n",
       "         [0.1140],\n",
       "         [0.1139],\n",
       "         [0.1138],\n",
       "         [0.1175],\n",
       "         [0.0999],\n",
       "         [0.0984],\n",
       "         [0.0923],\n",
       "         [0.0953],\n",
       "         [0.0970],\n",
       "         [0.1099],\n",
       "         [0.1118],\n",
       "         [0.1147],\n",
       "         [0.1134],\n",
       "         [0.1214],\n",
       "         [0.1190],\n",
       "         [0.1181],\n",
       "         [0.1127],\n",
       "         [0.1117],\n",
       "         [0.1144],\n",
       "         [0.0945],\n",
       "         [0.0936],\n",
       "         [0.1184],\n",
       "         [0.1191],\n",
       "         [0.1032],\n",
       "         [0.1042],\n",
       "         [0.1168],\n",
       "         [0.1187],\n",
       "         [0.1054],\n",
       "         [0.0987],\n",
       "         [0.1002],\n",
       "         [0.1093],\n",
       "         [0.0938],\n",
       "         [0.0897],\n",
       "         [0.0959],\n",
       "         [0.1182],\n",
       "         [0.1111],\n",
       "         [0.1087],\n",
       "         [0.1095],\n",
       "         [0.1180],\n",
       "         [0.1147],\n",
       "         [0.1099],\n",
       "         [0.1034],\n",
       "         [0.1045],\n",
       "         [0.1135],\n",
       "         [0.1145],\n",
       "         [0.1121],\n",
       "         [0.1115],\n",
       "         [0.1100],\n",
       "         [0.1081]]),\n",
       " 'state_ctx': tensor([[[ 3.0155, -0.3040,  0.8926,  ..., -0.0849,  1.0397, -1.1606],\n",
       "          [ 2.5629, -0.3726,  1.3197,  ..., -0.6407,  0.9507, -1.5841],\n",
       "          [ 2.9343, -0.5471,  0.4695,  ..., -0.4406,  0.7818, -1.0625],\n",
       "          ...,\n",
       "          [ 2.2707,  0.4428,  0.8472,  ..., -0.8710,  1.2296, -1.7126],\n",
       "          [ 2.6559, -0.0718,  0.4758,  ..., -1.0679,  0.9568, -0.9065],\n",
       "          [ 2.6129,  0.0805,  0.9323,  ..., -0.6275,  1.3792, -1.0960]],\n",
       " \n",
       "         [[ 3.0155, -0.3040,  0.8926,  ..., -0.0849,  1.0397, -1.1606],\n",
       "          [ 2.5629, -0.3726,  1.3197,  ..., -0.6407,  0.9507, -1.5841],\n",
       "          [ 2.9343, -0.5471,  0.4695,  ..., -0.4406,  0.7818, -1.0625],\n",
       "          ...,\n",
       "          [ 2.2707,  0.4428,  0.8472,  ..., -0.8710,  1.2296, -1.7126],\n",
       "          [ 2.6559, -0.0718,  0.4758,  ..., -1.0679,  0.9568, -0.9065],\n",
       "          [ 2.6129,  0.0805,  0.9323,  ..., -0.6275,  1.3792, -1.0960]],\n",
       " \n",
       "         [[ 3.0155, -0.3040,  0.8926,  ..., -0.0849,  1.0397, -1.1606],\n",
       "          [ 2.5629, -0.3726,  1.3197,  ..., -0.6407,  0.9507, -1.5841],\n",
       "          [ 2.9343, -0.5471,  0.4695,  ..., -0.4406,  0.7818, -1.0625],\n",
       "          ...,\n",
       "          [ 2.2707,  0.4428,  0.8472,  ..., -0.8710,  1.2296, -1.7126],\n",
       "          [ 2.6559, -0.0718,  0.4758,  ..., -1.0679,  0.9568, -0.9065],\n",
       "          [ 2.6129,  0.0805,  0.9323,  ..., -0.6275,  1.3792, -1.0960]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.3788, -1.1591,  0.4511,  ..., -0.1728,  0.9882, -0.8830],\n",
       "          [ 1.9639, -1.0563,  0.9891,  ..., -0.7417,  0.9795, -1.4197],\n",
       "          [ 2.3466, -1.2138,  0.3065,  ..., -0.6171,  0.9229, -0.9812],\n",
       "          ...,\n",
       "          [ 1.8057, -0.4900,  0.5171,  ..., -1.0736,  1.2565, -1.6847],\n",
       "          [ 2.2104, -0.8047,  0.2323,  ..., -1.2486,  1.0388, -0.8987],\n",
       "          [ 2.0853, -0.7075,  0.6938,  ..., -0.7673,  1.5071, -1.1255]],\n",
       " \n",
       "         [[ 2.3788, -1.1591,  0.4511,  ..., -0.1728,  0.9882, -0.8830],\n",
       "          [ 1.9609, -1.0617,  0.9882,  ..., -0.7580,  0.9866, -1.4192],\n",
       "          [ 2.3229, -1.3373,  0.1476,  ..., -0.6697,  0.8635, -1.0283],\n",
       "          ...,\n",
       "          [ 1.7677, -0.4899,  0.5428,  ..., -1.0235,  1.2849, -1.6473],\n",
       "          [ 2.1795, -0.8012,  0.2545,  ..., -1.2138,  1.0630, -0.8615],\n",
       "          [ 2.0549, -0.7092,  0.7126,  ..., -0.7363,  1.5296, -1.0938]],\n",
       " \n",
       "         [[ 2.3789, -1.1591,  0.4511,  ..., -0.1728,  0.9882, -0.8830],\n",
       "          [ 1.7880, -1.1499,  0.7747,  ..., -0.7211,  0.8745, -1.3775],\n",
       "          [ 2.1495, -1.3841,  0.0741,  ..., -0.5740,  0.8346, -0.9422],\n",
       "          ...,\n",
       "          [ 1.6813, -0.4777,  0.5870,  ..., -0.9255,  1.3350, -1.5663],\n",
       "          [ 2.1092, -0.7872,  0.2900,  ..., -1.1433,  1.1030, -0.7857],\n",
       "          [ 1.9877, -0.7032,  0.7426,  ..., -0.6723,  1.5667, -1.0251]]]),\n",
       " 'action_ctx': tensor([[[ 1.2670, -1.8658,  0.3010,  ...,  0.8636,  1.5969, -1.8373],\n",
       "          [ 0.6804, -2.3092,  0.1770,  ...,  0.5006,  1.5552, -1.9037],\n",
       "          [ 1.0380, -2.1259, -0.1391,  ...,  0.2163,  1.6728, -1.8728],\n",
       "          ...,\n",
       "          [ 1.0160, -1.8405, -0.0779,  ...,  0.5878,  1.6473, -1.7159],\n",
       "          [ 0.6831, -2.1078, -0.6686,  ...,  0.3076,  1.4930, -1.7710],\n",
       "          [ 1.4934, -1.6685, -0.4256,  ...,  0.3373,  1.9354, -1.7621]],\n",
       " \n",
       "         [[ 1.2670, -1.8658,  0.3010,  ...,  0.8636,  1.5969, -1.8373],\n",
       "          [ 0.6804, -2.3092,  0.1770,  ...,  0.5006,  1.5552, -1.9037],\n",
       "          [ 1.0380, -2.1259, -0.1391,  ...,  0.2163,  1.6728, -1.8728],\n",
       "          ...,\n",
       "          [ 1.0160, -1.8405, -0.0779,  ...,  0.5878,  1.6473, -1.7159],\n",
       "          [ 0.6831, -2.1078, -0.6686,  ...,  0.3076,  1.4930, -1.7710],\n",
       "          [ 1.4934, -1.6685, -0.4256,  ...,  0.3373,  1.9354, -1.7621]],\n",
       " \n",
       "         [[ 1.2670, -1.8658,  0.3010,  ...,  0.8636,  1.5969, -1.8373],\n",
       "          [ 0.6804, -2.3092,  0.1770,  ...,  0.5006,  1.5552, -1.9037],\n",
       "          [ 1.0380, -2.1259, -0.1391,  ...,  0.2163,  1.6728, -1.8728],\n",
       "          ...,\n",
       "          [ 1.0160, -1.8405, -0.0779,  ...,  0.5878,  1.6473, -1.7159],\n",
       "          [ 0.6831, -2.1078, -0.6686,  ...,  0.3076,  1.4930, -1.7710],\n",
       "          [ 1.4934, -1.6685, -0.4256,  ...,  0.3373,  1.9354, -1.7621]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.5026, -1.3985,  1.1657,  ...,  1.0881,  1.3834, -0.5958],\n",
       "          [ 1.1785, -1.9136,  1.2257,  ...,  0.8206,  1.2787, -0.8076],\n",
       "          [ 1.3018, -2.1360, -0.0788,  ...,  0.3232,  1.6155, -1.6722],\n",
       "          ...,\n",
       "          [ 1.5087, -1.3611,  0.8682,  ...,  0.6561,  1.3483, -0.5353],\n",
       "          [ 1.2119, -1.8834,  0.2064,  ...,  0.5197,  1.2626, -0.6946],\n",
       "          [ 1.8625, -1.3253,  0.4757,  ...,  0.4863,  1.7692, -0.6685]],\n",
       " \n",
       "         [[ 1.5612, -1.4156,  1.1866,  ...,  1.1015,  1.3919, -0.6143],\n",
       "          [ 0.9201, -2.3699,  0.1755,  ...,  0.5981,  1.4427, -1.7093],\n",
       "          [ 1.2802, -2.2451, -0.2110,  ...,  0.2962,  1.6065, -1.7195],\n",
       "          ...,\n",
       "          [ 1.4871, -1.3511,  0.8892,  ...,  0.7061,  1.3653, -0.4957],\n",
       "          [ 1.2073, -1.8818,  0.2159,  ...,  0.5702,  1.2747, -0.6603],\n",
       "          [ 1.9297, -1.3288,  0.4688,  ...,  0.5466,  1.8011, -0.6404]],\n",
       " \n",
       "         [[ 1.3429, -2.0323,  0.1353,  ...,  1.0092,  1.5335, -1.6621],\n",
       "          [ 0.8060, -2.4473,  0.0659,  ...,  0.6312,  1.4576, -1.6553],\n",
       "          [ 1.3257, -1.9521,  0.5958,  ...,  0.4705,  1.3135, -0.7542],\n",
       "          ...,\n",
       "          [ 1.4335, -1.3277,  0.9179,  ...,  0.8065,  1.3903, -0.4109],\n",
       "          [ 1.1803, -1.8724,  0.2222,  ...,  0.6718,  1.2874, -0.5884],\n",
       "          [ 1.9786, -1.3403,  0.4538,  ...,  0.6500,  1.8350, -0.5781]]]),\n",
       " 'state_tokens_pre': tensor([[[ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          ...,\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161]],\n",
       " \n",
       "         [[ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          ...,\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161]],\n",
       " \n",
       "         [[ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          ...,\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161],\n",
       "          [ 0.0982,  0.1210, -0.0037,  ..., -0.0129,  0.0596,  0.0161]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          ...,\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250]],\n",
       " \n",
       "         [[ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          ...,\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250]],\n",
       " \n",
       "         [[ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          ...,\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250],\n",
       "          [ 0.0558,  0.0868, -0.0036,  ..., -0.0798,  0.0859,  0.0250]]]),\n",
       " 'last_state_ctx': tensor([[ 2.6129,  0.0805,  0.9323,  ..., -0.6275,  1.3792, -1.0960],\n",
       "         [ 2.6129,  0.0805,  0.9323,  ..., -0.6275,  1.3792, -1.0960],\n",
       "         [ 2.6129,  0.0805,  0.9323,  ..., -0.6275,  1.3792, -1.0960],\n",
       "         ...,\n",
       "         [ 2.0853, -0.7075,  0.6938,  ..., -0.7673,  1.5071, -1.1255],\n",
       "         [ 2.0549, -0.7092,  0.7126,  ..., -0.7363,  1.5296, -1.0938],\n",
       "         [ 1.9877, -0.7032,  0.7426,  ..., -0.6723,  1.5667, -1.0251]]),\n",
       " 'last_action_ctx': tensor([[ 1.4934, -1.6685, -0.4256,  ...,  0.3373,  1.9354, -1.7621],\n",
       "         [ 1.4934, -1.6685, -0.4256,  ...,  0.3373,  1.9354, -1.7621],\n",
       "         [ 1.4934, -1.6685, -0.4256,  ...,  0.3373,  1.9354, -1.7621],\n",
       "         ...,\n",
       "         [ 1.8625, -1.3253,  0.4757,  ...,  0.4863,  1.7692, -0.6685],\n",
       "         [ 1.9297, -1.3288,  0.4688,  ...,  0.5466,  1.8011, -0.6404],\n",
       "         [ 1.9786, -1.3403,  0.4538,  ...,  0.6500,  1.8350, -0.5781]]),\n",
       " 'meta': tensor([[  0,   0],\n",
       "         [  0,   1],\n",
       "         [  0,   2],\n",
       "         [  0,   3],\n",
       "         [  0,   4],\n",
       "         [  0,   5],\n",
       "         [  0,   6],\n",
       "         [  0,   7],\n",
       "         [  0,   8],\n",
       "         [  0,   9],\n",
       "         [  0,  10],\n",
       "         [  0,  11],\n",
       "         [  0,  12],\n",
       "         [  0,  13],\n",
       "         [  0,  14],\n",
       "         [  0,  15],\n",
       "         [  0,  16],\n",
       "         [  0,  17],\n",
       "         [  0,  18],\n",
       "         [  0,  19],\n",
       "         [  0,  20],\n",
       "         [  0,  21],\n",
       "         [  0,  22],\n",
       "         [  0,  23],\n",
       "         [  0,  24],\n",
       "         [  0,  25],\n",
       "         [  0,  26],\n",
       "         [  0,  27],\n",
       "         [  0,  28],\n",
       "         [  0,  29],\n",
       "         [  0,  30],\n",
       "         [  0,  31],\n",
       "         [  0,  32],\n",
       "         [  0,  33],\n",
       "         [  0,  34],\n",
       "         [  0,  35],\n",
       "         [  0,  36],\n",
       "         [  0,  37],\n",
       "         [  0,  38],\n",
       "         [  0,  39],\n",
       "         [  0,  40],\n",
       "         [  0,  41],\n",
       "         [  0,  42],\n",
       "         [  0,  43],\n",
       "         [  0,  44],\n",
       "         [  0,  45],\n",
       "         [  0,  46],\n",
       "         [  0,  47],\n",
       "         [  0,  48],\n",
       "         [  0,  49],\n",
       "         [  0,  50],\n",
       "         [  0,  51],\n",
       "         [  0,  52],\n",
       "         [  0,  53],\n",
       "         [  0,  54],\n",
       "         [  0,  55],\n",
       "         [  0,  56],\n",
       "         [  0,  57],\n",
       "         [  0,  58],\n",
       "         [  0,  59],\n",
       "         [  0,  60],\n",
       "         [  0,  61],\n",
       "         [  0,  62],\n",
       "         [  0,  63],\n",
       "         [  0,  64],\n",
       "         [  0,  65],\n",
       "         [  0,  66],\n",
       "         [  0,  67],\n",
       "         [  0,  68],\n",
       "         [  0,  69],\n",
       "         [  0,  70],\n",
       "         [  0,  71],\n",
       "         [  0,  72],\n",
       "         [  0,  73],\n",
       "         [  0,  74],\n",
       "         [  0,  75],\n",
       "         [  0,  76],\n",
       "         [  0,  77],\n",
       "         [  0,  78],\n",
       "         [  0,  79],\n",
       "         [  0,  80],\n",
       "         [  0,  81],\n",
       "         [  0,  82],\n",
       "         [  0,  83],\n",
       "         [  0,  84],\n",
       "         [  0,  85],\n",
       "         [  0,  86],\n",
       "         [  0,  87],\n",
       "         [  0,  88],\n",
       "         [  0,  89],\n",
       "         [  0,  90],\n",
       "         [  0,  91],\n",
       "         [  0,  92],\n",
       "         [  0,  93],\n",
       "         [  0,  94],\n",
       "         [  0,  95],\n",
       "         [  0,  96],\n",
       "         [  0,  97],\n",
       "         [  0,  98],\n",
       "         [  0,  99],\n",
       "         [  0, 100],\n",
       "         [  0, 101],\n",
       "         [  0, 102],\n",
       "         [  0, 103],\n",
       "         [  0, 104],\n",
       "         [  0, 105],\n",
       "         [  0, 106],\n",
       "         [  0, 107],\n",
       "         [  0, 108],\n",
       "         [  0, 109],\n",
       "         [  0, 110],\n",
       "         [  0, 111],\n",
       "         [  0, 112],\n",
       "         [  0, 113],\n",
       "         [  0, 114],\n",
       "         [  0, 115],\n",
       "         [  0, 116],\n",
       "         [  0, 117],\n",
       "         [  0, 118],\n",
       "         [  0, 119],\n",
       "         [  0, 120],\n",
       "         [  0, 121],\n",
       "         [  0, 122],\n",
       "         [  0, 123],\n",
       "         [  0, 124],\n",
       "         [  0, 125],\n",
       "         [  0, 126],\n",
       "         [  0, 127],\n",
       "         [  0, 128],\n",
       "         [  0, 129],\n",
       "         [  0, 130],\n",
       "         [  0, 131],\n",
       "         [  0, 132],\n",
       "         [  0, 133],\n",
       "         [  0, 134],\n",
       "         [  0, 135],\n",
       "         [  0, 136],\n",
       "         [  0, 137],\n",
       "         [  0, 138],\n",
       "         [  0, 139],\n",
       "         [  0, 140],\n",
       "         [  0, 141],\n",
       "         [  0, 142],\n",
       "         [  0, 143],\n",
       "         [  0, 144],\n",
       "         [  0, 145],\n",
       "         [  0, 146],\n",
       "         [  0, 147],\n",
       "         [  0, 148],\n",
       "         [  0, 149],\n",
       "         [  0, 150],\n",
       "         [  0, 151],\n",
       "         [  0, 152],\n",
       "         [  0, 153],\n",
       "         [  0, 154],\n",
       "         [  0, 155],\n",
       "         [  0, 156],\n",
       "         [  0, 157],\n",
       "         [  0, 158],\n",
       "         [  0, 159],\n",
       "         [  0, 160],\n",
       "         [  0, 161],\n",
       "         [  0, 162],\n",
       "         [  0, 163],\n",
       "         [  0, 164],\n",
       "         [  0, 165],\n",
       "         [  0, 166],\n",
       "         [  0, 167],\n",
       "         [  0, 168],\n",
       "         [  0, 169],\n",
       "         [  0, 170],\n",
       "         [  0, 171],\n",
       "         [  0, 172],\n",
       "         [  0, 173],\n",
       "         [  0, 174],\n",
       "         [  0, 175],\n",
       "         [  0, 176],\n",
       "         [  0, 177],\n",
       "         [  0, 178],\n",
       "         [  0, 179],\n",
       "         [  0, 180],\n",
       "         [  0, 181],\n",
       "         [  0, 182],\n",
       "         [  0, 183],\n",
       "         [  0, 184],\n",
       "         [  0, 185],\n",
       "         [  0, 186],\n",
       "         [  0, 187],\n",
       "         [  0, 188],\n",
       "         [  0, 189],\n",
       "         [  0, 190],\n",
       "         [  0, 191],\n",
       "         [  0, 192],\n",
       "         [  0, 193],\n",
       "         [  0, 194],\n",
       "         [  0, 195],\n",
       "         [  0, 196],\n",
       "         [  0, 197],\n",
       "         [  0, 198],\n",
       "         [  0, 199],\n",
       "         [  0, 200],\n",
       "         [  0, 201],\n",
       "         [  0, 202],\n",
       "         [  0, 203],\n",
       "         [  0, 204],\n",
       "         [  0, 205],\n",
       "         [  0, 206],\n",
       "         [  0, 207],\n",
       "         [  0, 208],\n",
       "         [  0, 209],\n",
       "         [  0, 210],\n",
       "         [  0, 211],\n",
       "         [  0, 212],\n",
       "         [  0, 213],\n",
       "         [  0, 214],\n",
       "         [  0, 215],\n",
       "         [  0, 216],\n",
       "         [  0, 217],\n",
       "         [  0, 218],\n",
       "         [  0, 219],\n",
       "         [  0, 220],\n",
       "         [  0, 221],\n",
       "         [  0, 222],\n",
       "         [  0, 223],\n",
       "         [  0, 224],\n",
       "         [  0, 225],\n",
       "         [  0, 226],\n",
       "         [  0, 227],\n",
       "         [  0, 228],\n",
       "         [  0, 229],\n",
       "         [  0, 230],\n",
       "         [  0, 231],\n",
       "         [  0, 232],\n",
       "         [  0, 233],\n",
       "         [  0, 234],\n",
       "         [  0, 235],\n",
       "         [  0, 236],\n",
       "         [  0, 237],\n",
       "         [  0, 238],\n",
       "         [  0, 239],\n",
       "         [  0, 240],\n",
       "         [  0, 241],\n",
       "         [  0, 242],\n",
       "         [  0, 243],\n",
       "         [  0, 244],\n",
       "         [  0, 245],\n",
       "         [  0, 246],\n",
       "         [  0, 247],\n",
       "         [  0, 248],\n",
       "         [  0, 249],\n",
       "         [  0, 250],\n",
       "         [  0, 251],\n",
       "         [  0, 252],\n",
       "         [  0, 253],\n",
       "         [  0, 254],\n",
       "         [  0, 255]])}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006bf59-7c54-44e0-bc79-1a74619ffee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
